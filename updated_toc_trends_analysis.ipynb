{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd, imp\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update TOC trends analysis\n",
    "\n",
    "Tore has previously written code to calculate [Mann-Kendall (M-K)](https://cran.r-project.org/web/packages/trend/vignettes/trend.pdf) trend statistics and [Sen's slope](https://en.wikipedia.org/wiki/Theil%E2%80%93Sen_estimator) estimates for data series in RESA2. According to my notes from a meeting with Tore on 13/05/2016, the workflow goes something like this:\n",
    "\n",
    " 1. Run code to extract and summarise time series from RESA2, insert this data into *Mann-Kendall_Sen.xls*, then read the results back into a new table in RESA2 called e.g. `ICPW_STATISTICS`. <br><br>\n",
    " \n",
    " 2. Run the `ICPStat` query in *Icp-waters2001_2000.accdb* to summarise the data in `ICPW_STATISTICS`. This creates a new table currently called `aaa`, but Tore says he'll rename it to something more descriptive before he leaves. <br><br>\n",
    " \n",
    " 3. Run the `export()` subroutine in the `Export` module of *Icp-waters2001_2000.accdb* to reformat the `aaa` table and write the results to an Excel file.\n",
    " \n",
    "*Mann-Kendall_Sen.xls* is an early version of the popular Excel macro **MULTIMK/CONDMK**, which Tore has modified slightly for use in this analysis. (A more recent version of the same file is available [here](http://taurus.gg.bg.ut.ee/jaagus/MKtingtsirk.xls)). This Excel macro permits some quite sophisticated multivariate and conditional analyses, but as far as I can tell the TOC trends code is only making use of the most basic functionality - performing repeated independent trend tests on annually summarised time series.\n",
    "\n",
    "Unfortunately, although the workflow above makes sense, I've so far failed to find and run Tore's code for step 1 (I can find everything for steps 2 and 3, but not the code for interacting with the Excel workbook). It also seems a bit messy to be switching back and forth between RESA2, Excel and Access in this way, so the code here is a first step towards refactoring the whole analysis into Python.\n",
    "\n",
    "## 1. Test data\n",
    "\n",
    "The *Mann-Kendall_Sen.xls* file on the network already had some example ICPW data in it, which I can use to test my code. The raw input data and the results obtained from the Excel macro are saved as *mk_sen_test_data.xlsx*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ESO4</th>\n",
       "      <th>ESO4X</th>\n",
       "      <th>ECL</th>\n",
       "      <th>ESO4CL</th>\n",
       "      <th>TOC_DOC</th>\n",
       "      <th>ECAEMG</th>\n",
       "      <th>ECAXEMGX</th>\n",
       "      <th>ENO3</th>\n",
       "      <th>AL</th>\n",
       "      <th>ANC</th>\n",
       "      <th>ALK</th>\n",
       "      <th>HPLUSS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>2002</td>\n",
       "      <td>65.37472</td>\n",
       "      <td>37.48427</td>\n",
       "      <td>270.78103</td>\n",
       "      <td>336.15575</td>\n",
       "      <td>1.1</td>\n",
       "      <td>90.04695</td>\n",
       "      <td>26.95497</td>\n",
       "      <td>25.35714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-29.62386</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.45654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>196</td>\n",
       "      <td>2003</td>\n",
       "      <td>67.66492</td>\n",
       "      <td>41.80815</td>\n",
       "      <td>251.03658</td>\n",
       "      <td>318.70150</td>\n",
       "      <td>1.2</td>\n",
       "      <td>91.65460</td>\n",
       "      <td>33.16308</td>\n",
       "      <td>24.28571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16.01517</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7.58578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>196</td>\n",
       "      <td>2004</td>\n",
       "      <td>58.29593</td>\n",
       "      <td>37.40714</td>\n",
       "      <td>202.80371</td>\n",
       "      <td>261.09964</td>\n",
       "      <td>1.5</td>\n",
       "      <td>76.21036</td>\n",
       "      <td>28.95710</td>\n",
       "      <td>17.85714</td>\n",
       "      <td>116.04925</td>\n",
       "      <td>-10.20958</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.49541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196</td>\n",
       "      <td>2005</td>\n",
       "      <td>63.29272</td>\n",
       "      <td>31.04439</td>\n",
       "      <td>313.09057</td>\n",
       "      <td>376.38329</td>\n",
       "      <td>1.5</td>\n",
       "      <td>102.44073</td>\n",
       "      <td>29.49062</td>\n",
       "      <td>17.85714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.89069</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.91251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>196</td>\n",
       "      <td>2006</td>\n",
       "      <td>58.50413</td>\n",
       "      <td>33.60609</td>\n",
       "      <td>241.72849</td>\n",
       "      <td>300.23262</td>\n",
       "      <td>1.6</td>\n",
       "      <td>92.07006</td>\n",
       "      <td>35.74731</td>\n",
       "      <td>16.78571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.40248</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7.24436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>196</td>\n",
       "      <td>2007</td>\n",
       "      <td>57.25493</td>\n",
       "      <td>26.74975</td>\n",
       "      <td>296.16676</td>\n",
       "      <td>353.42169</td>\n",
       "      <td>1.9</td>\n",
       "      <td>97.15416</td>\n",
       "      <td>28.14731</td>\n",
       "      <td>19.64286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.34566</td>\n",
       "      <td>5.2920</td>\n",
       "      <td>3.38844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>196</td>\n",
       "      <td>2008</td>\n",
       "      <td>57.46313</td>\n",
       "      <td>26.95795</td>\n",
       "      <td>296.16676</td>\n",
       "      <td>353.62989</td>\n",
       "      <td>1.3</td>\n",
       "      <td>96.15616</td>\n",
       "      <td>27.14931</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.50689</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.89045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>196</td>\n",
       "      <td>2009</td>\n",
       "      <td>54.34013</td>\n",
       "      <td>21.51075</td>\n",
       "      <td>318.73184</td>\n",
       "      <td>373.07197</td>\n",
       "      <td>1.5</td>\n",
       "      <td>93.01387</td>\n",
       "      <td>23.63606</td>\n",
       "      <td>12.14286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.30612</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.36516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>196</td>\n",
       "      <td>2010</td>\n",
       "      <td>55.58933</td>\n",
       "      <td>31.47571</td>\n",
       "      <td>234.11277</td>\n",
       "      <td>289.70210</td>\n",
       "      <td>2.0</td>\n",
       "      <td>83.64120</td>\n",
       "      <td>29.09293</td>\n",
       "      <td>15.35714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.23056</td>\n",
       "      <td>5.2920</td>\n",
       "      <td>2.13796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>196</td>\n",
       "      <td>2011</td>\n",
       "      <td>46.63674</td>\n",
       "      <td>25.68985</td>\n",
       "      <td>203.36784</td>\n",
       "      <td>250.00458</td>\n",
       "      <td>2.3</td>\n",
       "      <td>91.07205</td>\n",
       "      <td>43.68734</td>\n",
       "      <td>12.14286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.07122</td>\n",
       "      <td>6.4445</td>\n",
       "      <td>2.04174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>196</td>\n",
       "      <td>2012</td>\n",
       "      <td>53.71553</td>\n",
       "      <td>23.79141</td>\n",
       "      <td>290.52548</td>\n",
       "      <td>344.24101</td>\n",
       "      <td>1.9</td>\n",
       "      <td>101.94173</td>\n",
       "      <td>34.24928</td>\n",
       "      <td>15.71429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.55875</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.29087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    STATION_ID  YEAR      ESO4     ESO4X        ECL     ESO4CL  TOC_DOC  \\\n",
       "0          196  2002  65.37472  37.48427  270.78103  336.15575      1.1   \n",
       "1          196  2003  67.66492  41.80815  251.03658  318.70150      1.2   \n",
       "2          196  2004  58.29593  37.40714  202.80371  261.09964      1.5   \n",
       "3          196  2005  63.29272  31.04439  313.09057  376.38329      1.5   \n",
       "4          196  2006  58.50413  33.60609  241.72849  300.23262      1.6   \n",
       "5          196  2007  57.25493  26.74975  296.16676  353.42169      1.9   \n",
       "6          196  2008  57.46313  26.95795  296.16676  353.62989      1.3   \n",
       "7          196  2009  54.34013  21.51075  318.73184  373.07197      1.5   \n",
       "8          196  2010  55.58933  31.47571  234.11277  289.70210      2.0   \n",
       "9          196  2011  46.63674  25.68985  203.36784  250.00458      2.3   \n",
       "10         196  2012  53.71553  23.79141  290.52548  344.24101      1.9   \n",
       "\n",
       "       ECAEMG  ECAXEMGX      ENO3         AL       ANC     ALK   HPLUSS  \n",
       "0    90.04695  26.95497  25.35714        NaN -29.62386  0.0000  6.45654  \n",
       "1    91.65460  33.16308  24.28571        NaN -16.01517  0.0000  7.58578  \n",
       "2    76.21036  28.95710  17.85714  116.04925 -10.20958  0.0000  5.49541  \n",
       "3   102.44073  29.49062  17.85714        NaN  -8.89069  0.0000  8.91251  \n",
       "4    92.07006  35.74731  16.78571        NaN  -0.40248  0.0000  7.24436  \n",
       "5    97.15416  28.14731  19.64286        NaN  -0.34566  5.2920  3.38844  \n",
       "6    96.15616  27.14931  15.00000        NaN  -4.50689  0.0000  3.89045  \n",
       "7    93.01387  23.63606  12.14286        NaN  -2.30612  0.0000  4.36516  \n",
       "8    83.64120  29.09293  15.35714        NaN  15.23056  5.2920  2.13796  \n",
       "9    91.07205  43.68734  12.14286        NaN  12.07122  6.4445  2.04174  \n",
       "10  101.94173  34.24928  15.71429        NaN  14.55875  0.0000  2.29087  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data and results from the Excel macro\n",
    "in_xlsx = (r'C:\\Data\\James_Work\\Staff\\Heleen_d_W\\ICP_Waters\\TOC_Trends_Analysis_2015'\n",
    "           r'\\Data\\mk_sen_test_data.xlsx')\n",
    "\n",
    "raw_df = pd.read_excel(in_xlsx, sheetname='input')\n",
    "res_df = pd.read_excel(in_xlsx, sheetname='results')\n",
    "\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par</th>\n",
       "      <th>non_missing</th>\n",
       "      <th>test_stat</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>mk_stat</th>\n",
       "      <th>mk_p_val</th>\n",
       "      <th>sen_slp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESO4</td>\n",
       "      <td>11</td>\n",
       "      <td>-43</td>\n",
       "      <td>12.845233</td>\n",
       "      <td>-3.347545</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>-1.457400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESO4X</td>\n",
       "      <td>11</td>\n",
       "      <td>-37</td>\n",
       "      <td>12.845233</td>\n",
       "      <td>-2.880446</td>\n",
       "      <td>0.003971</td>\n",
       "      <td>-1.701966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECL</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>12.806248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESO4CL</td>\n",
       "      <td>11</td>\n",
       "      <td>-3</td>\n",
       "      <td>12.845233</td>\n",
       "      <td>-0.233550</td>\n",
       "      <td>0.815335</td>\n",
       "      <td>-1.585009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOC_DOC</td>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "      <td>12.662280</td>\n",
       "      <td>2.764115</td>\n",
       "      <td>0.005708</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ECAEMG</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>12.845233</td>\n",
       "      <td>0.700649</td>\n",
       "      <td>0.483522</td>\n",
       "      <td>0.423846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ECAXEMGX</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>12.845233</td>\n",
       "      <td>0.700649</td>\n",
       "      <td>0.483522</td>\n",
       "      <td>0.267245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ENO3</td>\n",
       "      <td>11</td>\n",
       "      <td>-35</td>\n",
       "      <td>12.767145</td>\n",
       "      <td>-2.741412</td>\n",
       "      <td>0.006118</td>\n",
       "      <td>-0.964285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ANC</td>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "      <td>12.845233</td>\n",
       "      <td>3.347545</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>3.562240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ALK</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>9.933109</td>\n",
       "      <td>1.610775</td>\n",
       "      <td>0.107229</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HPLUSS</td>\n",
       "      <td>11</td>\n",
       "      <td>-33</td>\n",
       "      <td>12.845233</td>\n",
       "      <td>-2.569047</td>\n",
       "      <td>0.010198</td>\n",
       "      <td>-0.539823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         par  non_missing  test_stat    std_dev   mk_stat  mk_p_val   sen_slp\n",
       "0       ESO4           11        -43  12.845233 -3.347545  0.000815 -1.457400\n",
       "1      ESO4X           11        -37  12.845233 -2.880446  0.003971 -1.701966\n",
       "2        ECL           11          0  12.806248  0.000000  1.000000  0.000000\n",
       "3     ESO4CL           11         -3  12.845233 -0.233550  0.815335 -1.585009\n",
       "4    TOC_DOC           11         35  12.662280  2.764115  0.005708  0.100000\n",
       "5     ECAEMG           11          9  12.845233  0.700649  0.483522  0.423846\n",
       "6   ECAXEMGX           11          9  12.845233  0.700649  0.483522  0.267245\n",
       "7       ENO3           11        -35  12.767145 -2.741412  0.006118 -0.964285\n",
       "8         AL            1          0   0.000000       NaN       NaN       NaN\n",
       "9        ANC           11         43  12.845233  3.347545  0.000815  3.562240\n",
       "10       ALK           11         16   9.933109  1.610775  0.107229  0.000000\n",
       "11    HPLUSS           11        -33  12.845233 -2.569047  0.010198 -0.539823"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Statistical functions\n",
    "\n",
    "Looking at the output in the `ICPW_STATISTICS3` table of RESA2, we need to calculate the following statistcs (only some of which are output by the Excel macro):\n",
    "\n",
    " * Number of non-missing values\n",
    " * Median\n",
    " * Mean\n",
    " * Period over which data are available (start and end years)\n",
    " * Standard deviation (of the data)\n",
    " * Standard deviation (expected under the null hypothesis of the M-K test)\n",
    " * M-K statistic\n",
    " * Normalised M-K statistic $\\left(= \\frac{M-K \\; statistic}{Standard \\; deviation} \\right)$\n",
    " * M-K p-value\n",
    " * Sen's slope (a.k.a. the Theil-Sen slope)\n",
    "\n",
    "Most of these should be quite straightforward. We'll start off by defining a function to calculate the M-K statistic (note that Scipy already has a function for the Theil-Sen slope). We'll also define another function to bundle everything together and return a dataframe of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mk_test(x, stn_id, par, alpha=0.05):\n",
    "    \"\"\" Adapted from http://pydoc.net/Python/ambhas/0.4.0/ambhas.stats/\n",
    "        by Sat Kumar Tomer.\n",
    "    \n",
    "        Perform the MK test for monotonic trends. Uses the \"normal\n",
    "        approximation\" to determine significance and therefore should \n",
    "        only be used if the number of values is >= 10.\n",
    "    \n",
    "    Args:\n",
    "        x:     1D array of data\n",
    "        name:  Name for data series (string)\n",
    "        alpha: Significance level\n",
    "    \n",
    "    Returns:\n",
    "        var_s: Variance of test statistic\n",
    "        s:     M-K test statistic\n",
    "        z:     Normalised test statistic \n",
    "        p:     p-value of the significance test\n",
    "        trend: Whether to reject the null hypothesis (no trend) at\n",
    "               the specified significance level. One of: \n",
    "               'increasing', 'decreasing' or 'no trend'\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from scipy.stats import norm\n",
    "    \n",
    "    n = len(x)\n",
    "    \n",
    "    if n < 10:\n",
    "        print ('    Data series for %s at site %s has fewer than 10 non-null values. '\n",
    "               'Significance estimates may be unreliable.' % (par, int(stn_id)))\n",
    "    \n",
    "    # calculate S \n",
    "    s = 0\n",
    "    for k in xrange(n-1):\n",
    "        for j in xrange(k+1,n):\n",
    "            s += np.sign(x[j] - x[k])\n",
    "    \n",
    "    # calculate the unique data\n",
    "    unique_x = np.unique(x)\n",
    "    g = len(unique_x)\n",
    "    \n",
    "    # calculate the var(s)\n",
    "    if n == g: # there is no tie\n",
    "        var_s = (n*(n-1)*(2*n+5))/18.           \n",
    "    else: # there are some ties in data\n",
    "        tp = np.zeros(unique_x.shape)\n",
    "        for i in xrange(len(unique_x)):\n",
    "            tp[i] = sum(unique_x[i] == x)\n",
    "        # Sat Kumar's code has \"+ np.sum\", which is incorrect\n",
    "        var_s = (n*(n-1)*(2*n+5) - np.sum(tp*(tp-1)*(2*tp+5)))/18.\n",
    "    \n",
    "    if s>0:\n",
    "        z = (s - 1)/np.sqrt(var_s)\n",
    "    elif s == 0:\n",
    "            z = 0\n",
    "    elif s<0:\n",
    "        z = (s + 1)/np.sqrt(var_s)\n",
    "    else:\n",
    "        z = np.nan\n",
    "        \n",
    "    # calculate the p_value\n",
    "    p = 2*(1-norm.cdf(abs(z))) # two tail test\n",
    "    h = abs(z) > norm.ppf(1-alpha/2.) \n",
    "\n",
    "    if (z<0) and h:\n",
    "        trend = 'decreasing'\n",
    "    elif (z>0) and h:\n",
    "        trend = 'increasing'\n",
    "    elif np.isnan(z):\n",
    "        trend = np.nan\n",
    "    else:\n",
    "        trend = 'no trend'\n",
    "        \n",
    "    return var_s, s, z, p, trend\n",
    "\n",
    "def wc_stats(raw_df, st_yr=None, end_yr=None):\n",
    "    \"\"\" Calculate key statistics for the TOC trends analysis:\n",
    "        \n",
    "            'station_id'\n",
    "            'par_id'\n",
    "            'non_missing'\n",
    "            'median'\n",
    "            'mean'\n",
    "            'std_dev'\n",
    "            'period'\n",
    "            'mk_std_dev'\n",
    "            'mk_stat'\n",
    "            'norm_mk_stat'\n",
    "            'mk_p_val'\n",
    "            'trend'\n",
    "            'sen_slp'\n",
    "    \n",
    "    Args:\n",
    "        raw_df:   Dataframe with annual data for a single station. Columns must \n",
    "                  be: [station_id, year, par1, par2, ... parn]\n",
    "        st_yr:    First year to include in analysis. Pass None to start\n",
    "                  at the beginning of the series\n",
    "        end_year: Last year to include in analysis. Pass None to start\n",
    "                  at the beginning of the series\n",
    "    \n",
    "    Returns:\n",
    "        df of key statistics.\n",
    "    \"\"\"\n",
    "    import numpy as np, pandas as pd\n",
    "    from scipy.stats import theilslopes\n",
    "    \n",
    "    # Checking\n",
    "    df = raw_df.copy()\n",
    "    assert list(df.columns[:2]) == ['STATION_ID', 'YEAR'], 'Columns must be: [STATION_ID, YEAR, par1, par2, ... parn]'\n",
    "    assert len(df['STATION_ID'].unique()) == 1, 'You can only process data for one site at a time'\n",
    "    \n",
    "    # Get just the period of interest\n",
    "    if st_yr:\n",
    "        df = df.query('YEAR >= @st_yr')\n",
    "    if end_yr:\n",
    "        df = df.query('YEAR <= @end_yr')\n",
    "    \n",
    "    # Get stn_id\n",
    "    stn_id = df['STATION_ID'].iloc[0]\n",
    "    \n",
    "    # Tidy up df\n",
    "    df.index = df['YEAR']\n",
    "    df.sort_index(inplace=True)\n",
    "    del df['STATION_ID'], df['YEAR']\n",
    "    \n",
    "    # Container for results\n",
    "    data_dict = {'station_id':[],\n",
    "                 'par_id':[],\n",
    "                 'non_missing':[],\n",
    "                 'median':[],\n",
    "                 'mean':[],\n",
    "                 'std_dev':[],\n",
    "                 'period':[],\n",
    "                 'mk_std_dev':[],\n",
    "                 'mk_stat':[],\n",
    "                 'norm_mk_stat':[],\n",
    "                 'mk_p_val':[],\n",
    "                 'trend':[],\n",
    "                 'sen_slp':[]}\n",
    "    \n",
    "    # Loop over pars\n",
    "    for col in df.columns:\n",
    "        # 1. Station ID\n",
    "        data_dict['station_id'].append(stn_id)\n",
    "        \n",
    "        # 2. Par ID\n",
    "        data_dict['par_id'].append(col)\n",
    "        \n",
    "        # 3. Non-missing\n",
    "        data_dict['non_missing'].append(pd.notnull(df[col]).sum())\n",
    "        \n",
    "        # 4. Median\n",
    "        data_dict['median'].append(df[col].median())\n",
    "        \n",
    "        # 5. Mean\n",
    "        data_dict['mean'].append(df[col].mean())\n",
    "        \n",
    "        # 6. Std dev\n",
    "        data_dict['std_dev'].append(df[col].std())\n",
    "        \n",
    "        # 7. Period\n",
    "        st_yr = df.index.min()\n",
    "        end_yr = df.index.max()\n",
    "        per = '%s-%s' % (st_yr, end_yr)\n",
    "        data_dict['period'].append(per)\n",
    "\n",
    "        # 8. M-K test\n",
    "        # Drop missing values\n",
    "        mk_df = df[[col]].dropna(how='any')\n",
    "        \n",
    "        # Only run stats if more than 1 valid value\n",
    "        if len(mk_df) > 1:\n",
    "            var_s, s, z, p, trend = mk_test(mk_df[col].values, stn_id, col)\n",
    "            data_dict['mk_std_dev'].append(np.sqrt(var_s)) \n",
    "            data_dict['mk_stat'].append(s)\n",
    "            data_dict['norm_mk_stat'].append(z)\n",
    "            data_dict['mk_p_val'].append(p)\n",
    "            data_dict['trend'].append(trend)      \n",
    "\n",
    "            # 8. Sen's slope\n",
    "            # First element of output gives median slope. Other results could\n",
    "            # also be useful - see docs\n",
    "            sslp = theilslopes(mk_df[col].values, mk_df.index, 0.95)[0]\n",
    "            data_dict['sen_slp'].append(sslp)\n",
    "            \n",
    "        # Otherwise all NaN\n",
    "        else:\n",
    "            for par in ['mk_std_dev', 'mk_stat', 'norm_mk_stat', \n",
    "                        'mk_p_val', 'trend', 'sen_slp']:\n",
    "                data_dict[par].append(np.nan)\n",
    "    \n",
    "    # Build to df\n",
    "    res_df = pd.DataFrame(data_dict)\n",
    "    res_df = res_df[['station_id', 'par_id', 'period', 'non_missing',\n",
    "                     'mean', 'median', 'std_dev', 'mk_stat', 'norm_mk_stat',\n",
    "                     'mk_p_val', 'mk_std_dev', 'trend', 'sen_slp']]    \n",
    "    \n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Perform comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par_id</th>\n",
       "      <th>period</th>\n",
       "      <th>non_missing</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>mk_stat</th>\n",
       "      <th>norm_mk_stat</th>\n",
       "      <th>mk_p_val</th>\n",
       "      <th>mk_std_dev</th>\n",
       "      <th>trend</th>\n",
       "      <th>sen_slp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESO4</td>\n",
       "      <td>2002-2012</td>\n",
       "      <td>11</td>\n",
       "      <td>58.012019</td>\n",
       "      <td>57.46313</td>\n",
       "      <td>5.862422</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-3.269696</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>12.845233</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-1.457400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESO4X</td>\n",
       "      <td>2002-2012</td>\n",
       "      <td>11</td>\n",
       "      <td>30.684133</td>\n",
       "      <td>31.04439</td>\n",
       "      <td>6.406605</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>-2.802596</td>\n",
       "      <td>0.005069</td>\n",
       "      <td>12.845233</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-1.701966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECL</td>\n",
       "      <td>2002-2012</td>\n",
       "      <td>11</td>\n",
       "      <td>265.319257</td>\n",
       "      <td>270.78103</td>\n",
       "      <td>41.453419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.806248</td>\n",
       "      <td>no trend</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESO4CL</td>\n",
       "      <td>2002-2012</td>\n",
       "      <td>11</td>\n",
       "      <td>323.331276</td>\n",
       "      <td>336.15575</td>\n",
       "      <td>43.184790</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.155700</td>\n",
       "      <td>0.876270</td>\n",
       "      <td>12.845233</td>\n",
       "      <td>no trend</td>\n",
       "      <td>-1.585009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOC_DOC</td>\n",
       "      <td>2002-2012</td>\n",
       "      <td>11</td>\n",
       "      <td>1.618182</td>\n",
       "      <td>1.50000</td>\n",
       "      <td>0.368288</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.685140</td>\n",
       "      <td>0.007250</td>\n",
       "      <td>12.662280</td>\n",
       "      <td>increasing</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ECAEMG</td>\n",
       "      <td>2002-2012</td>\n",
       "      <td>11</td>\n",
       "      <td>92.309261</td>\n",
       "      <td>92.07006</td>\n",
       "      <td>7.587119</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.622799</td>\n",
       "      <td>0.533417</td>\n",
       "      <td>12.845233</td>\n",
       "      <td>no trend</td>\n",
       "      <td>0.423846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ECAXEMGX</td>\n",
       "      <td>2002-2012</td>\n",
       "      <td>11</td>\n",
       "      <td>30.934119</td>\n",
       "      <td>29.09293</td>\n",
       "      <td>5.498533</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.622799</td>\n",
       "      <td>0.533417</td>\n",
       "      <td>12.845233</td>\n",
       "      <td>no trend</td>\n",
       "      <td>0.267245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ENO3</td>\n",
       "      <td>2002-2012</td>\n",
       "      <td>11</td>\n",
       "      <td>17.467532</td>\n",
       "      <td>16.78571</td>\n",
       "      <td>4.295982</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>-2.663086</td>\n",
       "      <td>0.007743</td>\n",
       "      <td>12.767145</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-0.964285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AL</td>\n",
       "      <td>2002-2012</td>\n",
       "      <td>1</td>\n",
       "      <td>116.049250</td>\n",
       "      <td>116.04925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ANC</td>\n",
       "      <td>2002-2012</td>\n",
       "      <td>11</td>\n",
       "      <td>-2.767265</td>\n",
       "      <td>-2.30612</td>\n",
       "      <td>13.596531</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.269696</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>12.845233</td>\n",
       "      <td>increasing</td>\n",
       "      <td>3.562240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ALK</td>\n",
       "      <td>2002-2012</td>\n",
       "      <td>11</td>\n",
       "      <td>1.548045</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.667981</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.510101</td>\n",
       "      <td>0.131018</td>\n",
       "      <td>9.933110</td>\n",
       "      <td>no trend</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HPLUSS</td>\n",
       "      <td>2002-2012</td>\n",
       "      <td>11</td>\n",
       "      <td>4.891747</td>\n",
       "      <td>4.36516</td>\n",
       "      <td>2.403797</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>-2.491197</td>\n",
       "      <td>0.012731</td>\n",
       "      <td>12.845233</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-0.539823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      par_id     period  non_missing        mean     median    std_dev  \\\n",
       "0       ESO4  2002-2012           11   58.012019   57.46313   5.862422   \n",
       "1      ESO4X  2002-2012           11   30.684133   31.04439   6.406605   \n",
       "2        ECL  2002-2012           11  265.319257  270.78103  41.453419   \n",
       "3     ESO4CL  2002-2012           11  323.331276  336.15575  43.184790   \n",
       "4    TOC_DOC  2002-2012           11    1.618182    1.50000   0.368288   \n",
       "5     ECAEMG  2002-2012           11   92.309261   92.07006   7.587119   \n",
       "6   ECAXEMGX  2002-2012           11   30.934119   29.09293   5.498533   \n",
       "7       ENO3  2002-2012           11   17.467532   16.78571   4.295982   \n",
       "8         AL  2002-2012            1  116.049250  116.04925        NaN   \n",
       "9        ANC  2002-2012           11   -2.767265   -2.30612  13.596531   \n",
       "10       ALK  2002-2012           11    1.548045    0.00000   2.667981   \n",
       "11    HPLUSS  2002-2012           11    4.891747    4.36516   2.403797   \n",
       "\n",
       "    mk_stat  norm_mk_stat  mk_p_val  mk_std_dev       trend   sen_slp  \n",
       "0     -43.0     -3.269696  0.001077   12.845233  decreasing -1.457400  \n",
       "1     -37.0     -2.802596  0.005069   12.845233  decreasing -1.701966  \n",
       "2       0.0      0.000000  1.000000   12.806248    no trend  0.000000  \n",
       "3      -3.0     -0.155700  0.876270   12.845233    no trend -1.585009  \n",
       "4      35.0      2.685140  0.007250   12.662280  increasing  0.100000  \n",
       "5       9.0      0.622799  0.533417   12.845233    no trend  0.423846  \n",
       "6       9.0      0.622799  0.533417   12.845233    no trend  0.267245  \n",
       "7     -35.0     -2.663086  0.007743   12.767145  decreasing -0.964285  \n",
       "8       NaN           NaN       NaN         NaN         NaN       NaN  \n",
       "9      43.0      3.269696  0.001077   12.845233  increasing  3.562240  \n",
       "10     16.0      1.510101  0.131018    9.933110    no trend  0.000000  \n",
       "11    -33.0     -2.491197  0.012731   12.845233  decreasing -0.539823  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run analysis on test data and print results\n",
    "out_df = wc_stats(raw_df)\n",
    "del out_df['station_id']\n",
    "out_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And below is the output from the Excel macro for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par</th>\n",
       "      <th>non_missing</th>\n",
       "      <th>test_stat</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>mk_stat</th>\n",
       "      <th>mk_p_val</th>\n",
       "      <th>sen_slp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESO4</td>\n",
       "      <td>11</td>\n",
       "      <td>-43</td>\n",
       "      <td>12.845233</td>\n",
       "      <td>-3.347545</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>-1.457400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESO4X</td>\n",
       "      <td>11</td>\n",
       "      <td>-37</td>\n",
       "      <td>12.845233</td>\n",
       "      <td>-2.880446</td>\n",
       "      <td>0.003971</td>\n",
       "      <td>-1.701966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECL</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>12.806248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESO4CL</td>\n",
       "      <td>11</td>\n",
       "      <td>-3</td>\n",
       "      <td>12.845233</td>\n",
       "      <td>-0.233550</td>\n",
       "      <td>0.815335</td>\n",
       "      <td>-1.585009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOC_DOC</td>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "      <td>12.662280</td>\n",
       "      <td>2.764115</td>\n",
       "      <td>0.005708</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ECAEMG</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>12.845233</td>\n",
       "      <td>0.700649</td>\n",
       "      <td>0.483522</td>\n",
       "      <td>0.423846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ECAXEMGX</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>12.845233</td>\n",
       "      <td>0.700649</td>\n",
       "      <td>0.483522</td>\n",
       "      <td>0.267245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ENO3</td>\n",
       "      <td>11</td>\n",
       "      <td>-35</td>\n",
       "      <td>12.767145</td>\n",
       "      <td>-2.741412</td>\n",
       "      <td>0.006118</td>\n",
       "      <td>-0.964285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ANC</td>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "      <td>12.845233</td>\n",
       "      <td>3.347545</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>3.562240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ALK</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>9.933109</td>\n",
       "      <td>1.610775</td>\n",
       "      <td>0.107229</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HPLUSS</td>\n",
       "      <td>11</td>\n",
       "      <td>-33</td>\n",
       "      <td>12.845233</td>\n",
       "      <td>-2.569047</td>\n",
       "      <td>0.010198</td>\n",
       "      <td>-0.539823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         par  non_missing  test_stat    std_dev   mk_stat  mk_p_val   sen_slp\n",
       "0       ESO4           11        -43  12.845233 -3.347545  0.000815 -1.457400\n",
       "1      ESO4X           11        -37  12.845233 -2.880446  0.003971 -1.701966\n",
       "2        ECL           11          0  12.806248  0.000000  1.000000  0.000000\n",
       "3     ESO4CL           11         -3  12.845233 -0.233550  0.815335 -1.585009\n",
       "4    TOC_DOC           11         35  12.662280  2.764115  0.005708  0.100000\n",
       "5     ECAEMG           11          9  12.845233  0.700649  0.483522  0.423846\n",
       "6   ECAXEMGX           11          9  12.845233  0.700649  0.483522  0.267245\n",
       "7       ENO3           11        -35  12.767145 -2.741412  0.006118 -0.964285\n",
       "8         AL            1          0   0.000000       NaN       NaN       NaN\n",
       "9        ANC           11         43  12.845233  3.347545  0.000815  3.562240\n",
       "10       ALK           11         16   9.933109  1.610775  0.107229  0.000000\n",
       "11    HPLUSS           11        -33  12.845233 -2.569047  0.010198 -0.539823"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My code gives near-identical results to those from the Excel macro, although there are a few edge cases that might be worth investigating further. For example, if there are fewer than 10 non-null values, my code currently prints a warning. I'm not sure exactly what the Excel macro does yet, but in general it seems that for fewer than 10 values it's necessary to use a lookup table (see e.g. the `Instructions` sheet of the file [here](https://www.google.no/url?sa=t&rct=j&q=&esrc=s&source=web&cd=4&cad=rja&uact=8&ved=0ahUKEwia2cy5t_LNAhVECpoKHVngCqsQFggtMAM&url=https%3A%2F%2Fwww.researchgate.net%2Ffile.PostFileLoader.html%3Fid%3D55bba3666225ff21e88b4569%26assetKey%3DAS%253A273823084023809%25401442295918401&usg=AFQjCNGHCJHO6ab7otL2RMzw9zh7eaqTDg&sig2=sbLmEgIlfwOzJqOKO3gq-g&bvm=bv.126993452,d.bGs)).\n",
    "\n",
    "## 4. Get data from RESA2\n",
    "\n",
    "The next step is to read the correct data directly from RESA2 and summarise it to look like `raw_df`, above. Start off by connecting to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use custom RESA2 function to connect to db\n",
    "r2_func_path = r'C:\\Data\\James_Work\\Staff\\Heleen_d_W\\ICP_Waters\\Upload_Template\\useful_resa2_code.py'\n",
    "resa2 = imp.load_source('useful_resa2_code', r2_func_path)\n",
    "\n",
    "engine, conn = resa2.connect_to_resa2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the `ICPW_STATISTICS` table in RESA2, it seems as though trends have been assessed for **14 parameters** and several **different time periods** for each site of interest. The length and number of time periods vary from site to site, so I'll need to **check with Heleen** regarding how these varaibles should be chosen. The 14 parameters are as follows:\n",
    "\n",
    " * ESO4\n",
    " * ESO4X\n",
    " * ECl\n",
    " * ESO4Cl\n",
    " * TOC_DOC\n",
    " * ECaEMg\n",
    " * ECaXEMgX\n",
    " * ENO3\n",
    " * Al\n",
    " * ANC\n",
    " * ALK\n",
    " * HPLUS\n",
    " * ESO4EClENO3\n",
    " * ENO3DIVENO3ESO4X\n",
    " \n",
    "Many of these quantities are unfamiliar to me, but presumably the equations for calculating them can be found in Tore's code (which I can't find at present). **Check with Heleen whether all of these are still required** and find equations as necessary.\n",
    "\n",
    "The other issue is how to aggregate the values in the database from their original temporal resolution to annual summaries. I assume the **median** annual value is probably appropriate in most cases, but it would be good to know what Tore did previosuly.\n",
    "\n",
    "For now, I'll focus on:\n",
    "\n",
    " 1. Extracting the data from the database for a specified time period, <br><br>\n",
    " \n",
    " 2. Calculating the required water chemistry parameters, <br><br>\n",
    " \n",
    " 3. Taking annual medians and <br><br>\n",
    " \n",
    " 4. Estimating the trend statistics.\n",
    "\n",
    "It should then be fairly easy to modify this code later as necessary.\n",
    "\n",
    "### 4.1. Equations\n",
    "\n",
    "Some of the quantities listed above are straightforward to calculate. \n",
    "\n",
    "#### 4.1.1. Micro-equivalents per litre\n",
    "\n",
    "The Es in the parameter names are just unit conversions to micro-equivalents per litre:\n",
    "\n",
    "$$EPAR \\; (\\mu eq/l) = \\frac{1.10^6 * valency}{molar \\; mass \\; (g/mol)} * PAR \\; (g/l)$$\n",
    "\n",
    "Molar masses and valencies for the key species listed above are given in the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molar_mass</th>\n",
       "      <th>valency</th>\n",
       "      <th>resa2_ref_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SO4</th>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>0.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cl</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ca</th>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mg</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO3-N</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       molar_mass  valency resa2_ref_ratio\n",
       "SO4            96        2           0.103\n",
       "Cl             35        1               1\n",
       "Ca             40        2           0.037\n",
       "Mg             24        2           0.196\n",
       "NO3-N          14        1             N/A"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tabulate chemical properties\n",
    "chem_dict = {'molar_mass':[96, 35, 40, 24, 14],\n",
    "             'valency':[2, 1, 2, 2, 1],\n",
    "             'resa2_ref_ratio':[0.103, 1., 0.037, 0.196, 'N/A']}\n",
    "\n",
    "chem_df = pd.DataFrame(chem_dict, index=['SO4', 'Cl', 'Ca', 'Mg', 'NO3-N'])\n",
    "chem_df = chem_df[['molar_mass', 'valency', 'resa2_ref_ratio']]\n",
    "\n",
    "chem_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2. Sea-salt corrected values\n",
    "\n",
    "The Xs are sea-salt corrected values (also sometimes denoted with an asterisk e.g. Ca\\*). They are calculated by comparison to chloride concentrations, which are generall assumed to be conservative. The usual equation is:\n",
    "\n",
    "$$PARX = PAR_{sample} - \\left[ \\left( \\frac{PAR}{Cl} \\right)_{ref} * Cl_{sample} \\right]$$\n",
    "\n",
    "where $PAR_{sample}$ and $Cl_{sample}$ are the concentrations measured in the lake or river and $\\left( \\frac{PAR}{Cl} \\right)_{ref}$ is (ideally) the long-term average concentration in incoming rainwater. In some cases the reference values are simply taken from sea water concentrations (ignoring effects such as evaporative fractionation etc.). \n",
    "\n",
    "I'm not sure what values to assume, but by rearranging the above equations and applying it to data extarcted from RESA2 I can back-calculate the reference values. For example, brief testing using data from Italy, Switzerland and the Czech Republic implies that RESA2 uses a **standard reference value for sulphate of 0.103**.\n",
    "\n",
    "The reference ratios inferred from RESA2 for the key species listed are given in the table above.\n",
    "\n",
    "**NB:** In doing this I've identified some additional erros in the database, where this correction has not beeen performed correctly. For some reason, ESO4X values have been set to zero, despite valid ESO4 and ECl measurements being available. The problem only affects a handful od sample, but could be enough to generate false trends. **Return to this later?**\n",
    "\n",
    "**NB2:** Leah's experiences with the RECOVER project suggest that assuming a single reference concentration for all countires in the world is a bad idea. For example, I believe in e.g. the Czech Republic and Italy it is usual **not** to calculate sea-salt corrected concentrations at all, because most of the chloride input comes from industry rather than marine sources. Rainwater concentrations are also likely to vary dramatically from place to place, especially given the range of geographic and climatic conditions covered by this project. **Check with Heleen**.\n",
    "\n",
    "#### 4.1.3. ANC\n",
    "\n",
    "**Need to calculate this ANC, ALK, HPLUS and ENO3DIVENO3ESO4X.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Choose projects\n",
    "\n",
    "The first step is to specify a list of RESA2 projects and get the stations associated with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23499</td>\n",
       "      <td>CZ01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23500</td>\n",
       "      <td>CZ02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23501</td>\n",
       "      <td>CZ03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23502</td>\n",
       "      <td>CZ04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23503</td>\n",
       "      <td>CZ05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23504</td>\n",
       "      <td>CZ06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33325</td>\n",
       "      <td>CZ07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37745</td>\n",
       "      <td>CZ08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33326</td>\n",
       "      <td>CZ09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id station_code\n",
       "0       23499         CZ01\n",
       "1       23500         CZ02\n",
       "2       23501         CZ03\n",
       "3       23502         CZ04\n",
       "4       23503         CZ05\n",
       "5       23504         CZ06\n",
       "6       33325         CZ07\n",
       "7       37745         CZ08\n",
       "8       33326         CZ09"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get stations for a specified list of projects\n",
    "proj_list = ['ICPW_TOCTRENDS_2015_CZ', 'ICPW_TOCTRENDS_2015_IT']\n",
    "\n",
    "sql = ('SELECT station_id, station_code '\n",
    "       'FROM resa2.stations '\n",
    "       'WHERE station_id IN (SELECT UNIQUE(station_id) '\n",
    "                            'FROM resa2.projects_stations '\n",
    "                            'WHERE project_id IN (SELECT project_id '\n",
    "                            'FROM resa2.projects '\n",
    "                            'WHERE project_name IN %s))'\n",
    "                            % str(tuple(proj_list)))\n",
    "\n",
    "stn_df = pd.read_sql(sql, engine)\n",
    "\n",
    "stn_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Extract time series\n",
    "\n",
    "The next step is to get time series for the desired parameters for each of these stations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Specify parameters of interest\n",
    "par_list = ['SO4', 'Cl', 'Ca', 'Mg', 'NO3-N', 'TOC', 'Al']\n",
    "\n",
    "if 'DOC' in par_list:\n",
    "    print ('The database treats DOC and TOC similarly.\\n'\n",
    "           'You should probably enter \"TOC\" instead')\n",
    "    \n",
    "# Check pars are valid\n",
    "if len(par_list)==1:  \n",
    "    sql = (\"SELECT * FROM resa2.parameter_definitions \"\n",
    "           \"WHERE name = '%s'\" % par_list[0])\n",
    "else:\n",
    "    sql = ('SELECT * FROM resa2.parameter_definitions '\n",
    "           'WHERE name in %s' % str(tuple(par_list)))\n",
    "    \n",
    "par_df = pd.read_sql_query(sql, engine)\n",
    "\n",
    "assert len(par_df) == len(par_list), 'One or more parameters not valid.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>sample_date</th>\n",
       "      <th>Al</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Cl</th>\n",
       "      <th>Mg</th>\n",
       "      <th>NO3-N</th>\n",
       "      <th>SO4</th>\n",
       "      <th>TOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23499</td>\n",
       "      <td>1984-06-04</td>\n",
       "      <td>929.0</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.81</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23499</td>\n",
       "      <td>1984-08-04</td>\n",
       "      <td>840.0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.60</td>\n",
       "      <td>964.0</td>\n",
       "      <td>6.51</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23499</td>\n",
       "      <td>1985-06-05</td>\n",
       "      <td>851.0</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23499</td>\n",
       "      <td>1986-06-06</td>\n",
       "      <td>918.0</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23499</td>\n",
       "      <td>1986-08-06</td>\n",
       "      <td>795.0</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.77</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id sample_date     Al    Ca    Cl    Mg  NO3-N   SO4  TOC\n",
       "0       23499  1984-06-04  929.0  1.08  0.90  0.65    NaN  6.81  3.9\n",
       "1       23499  1984-08-04  840.0  1.05  0.92  0.60  964.0  6.51  4.2\n",
       "2       23499  1985-06-05  851.0  1.01  0.89  0.58    NaN  6.85  NaN\n",
       "3       23499  1986-06-06  918.0  1.07  0.99  0.56    NaN  7.01  NaN\n",
       "4       23499  1986-08-06  795.0  1.01  1.07  0.54    NaN  6.77  NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get results for ALL pars for sites and period of interest\n",
    "if len(stn_df)==1:\n",
    "    sql = (\"SELECT * FROM resa2.water_chemistry_values2 \"\n",
    "           \"WHERE sample_id IN (SELECT water_sample_id FROM resa2.water_samples \"\n",
    "                               \"WHERE station_id = %s)\"\n",
    "                               % stn_df['station_id'].iloc[0])    \n",
    "else:\n",
    "    sql = (\"SELECT * FROM resa2.water_chemistry_values2 \"\n",
    "           \"WHERE sample_id IN (SELECT water_sample_id FROM resa2.water_samples \"\n",
    "                               \"WHERE station_id IN %s)\"\n",
    "                               % str(tuple(stn_df['station_id'].values)))\n",
    "    \n",
    "wc_df = pd.read_sql_query(sql, engine)\n",
    "\n",
    "# Get all sample dates for sites and period of interest\n",
    "if len(stn_df)==1:\n",
    "    sql = (\"SELECT water_sample_id, station_id, sample_date \"\n",
    "           \"FROM resa2.water_samples \"\n",
    "           \"WHERE station_id = %s \" % stn_df['station_id'].iloc[0])    \n",
    "else:\n",
    "    sql = (\"SELECT water_sample_id, station_id, sample_date \"\n",
    "           \"FROM resa2.water_samples \"\n",
    "           \"WHERE station_id IN %s \" % str(tuple(stn_df['station_id'].values)))\n",
    "    \n",
    "samp_df = pd.read_sql_query(sql, engine)\n",
    "\n",
    "# Join in par IDs based on method IDs\n",
    "sql = ('SELECT * FROM resa2.wc_parameters_methods')\n",
    "meth_par_df = pd.read_sql_query(sql, engine)\n",
    "\n",
    "wc_df = pd.merge(wc_df, meth_par_df, how='left',\n",
    "                 left_on='method_id', right_on='wc_method_id')\n",
    "\n",
    "# Get just the parameters of interest\n",
    "wc_df = wc_df.query('wc_parameter_id in %s' % str(tuple(par_df['parameter_id'].values)))\n",
    "\n",
    "# Join in sample dates\n",
    "wc_df = pd.merge(wc_df, samp_df, how='left',\n",
    "                 left_on='sample_id', right_on='water_sample_id')\n",
    "\n",
    "# Join in parameter units\n",
    "sql = ('SELECT * FROM resa2.parameter_definitions')\n",
    "all_par_df = pd.read_sql_query(sql, engine)\n",
    "\n",
    "wc_df = pd.merge(wc_df, all_par_df, how='left',\n",
    "                 left_on='wc_parameter_id', right_on='parameter_id')\n",
    "\n",
    "# Join in station codes\n",
    "wc_df = pd.merge(wc_df, stn_df, how='left',\n",
    "                 left_on='station_id', right_on='station_id')\n",
    "\n",
    "# Convert units\n",
    "wc_df['value'] = wc_df['value'] * wc_df['conversion_factor']\n",
    "\n",
    "# Extract columns of interest\n",
    "wc_df = wc_df[['station_id', 'sample_date', 'name', 'value']]\n",
    "\n",
    "# Unstack\n",
    "wc_df.set_index(['station_id', 'sample_date', 'name'], inplace=True)\n",
    "wc_df = wc_df.unstack(level='name')\n",
    "wc_df.columns = wc_df.columns.droplevel()\n",
    "wc_df.reset_index(inplace=True)\n",
    "wc_df.columns.name = None\n",
    "\n",
    "wc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Aggregate to annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Al</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Cl</th>\n",
       "      <th>Mg</th>\n",
       "      <th>NO3-N</th>\n",
       "      <th>SO4</th>\n",
       "      <th>TOC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_id</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">23499</th>\n",
       "      <th>1984</th>\n",
       "      <td>884.5</td>\n",
       "      <td>1.065</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.625</td>\n",
       "      <td>964.0</td>\n",
       "      <td>6.660</td>\n",
       "      <td>4.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>851.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.850</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>856.5</td>\n",
       "      <td>1.040</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>750.0</td>\n",
       "      <td>1.100</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.620</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>795.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.075</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Al     Ca    Cl     Mg  NO3-N    SO4   TOC\n",
       "station_id year                                               \n",
       "23499      1984  884.5  1.065  0.91  0.625  964.0  6.660  4.05\n",
       "           1985  851.0  1.010  0.89  0.580    NaN  6.850   NaN\n",
       "           1986  856.5  1.040  1.03  0.550    NaN  6.890   NaN\n",
       "           1987  750.0  1.100  1.03  0.540    NaN  6.620   NaN\n",
       "           1988  795.0  1.010  0.79  0.555    NaN  6.075   NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract year from date column\n",
    "wc_df['year'] = wc_df['sample_date'].map(lambda x: x.year)\n",
    "del wc_df['sample_date']\n",
    "\n",
    "# Groupby station_id and year\n",
    "grpd = wc_df.groupby(['station_id', 'year'])\n",
    "\n",
    "# Calculate median\n",
    "wc_df = grpd.agg('median')\n",
    "\n",
    "wc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Convert units and apply sea-salt correction\n",
    "\n",
    "I haven't calculated all 14 parameters here, as I'm not sure exactly what they all are. The ones I'm reasonably certain of are included below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>year</th>\n",
       "      <th>Al</th>\n",
       "      <th>TOC</th>\n",
       "      <th>ESO4</th>\n",
       "      <th>ECl</th>\n",
       "      <th>EMg</th>\n",
       "      <th>ECa</th>\n",
       "      <th>ENO3</th>\n",
       "      <th>ESO4X</th>\n",
       "      <th>EMgX</th>\n",
       "      <th>ECaX</th>\n",
       "      <th>ESO4_ECl</th>\n",
       "      <th>ECa_EMg</th>\n",
       "      <th>ECaX_EMgX</th>\n",
       "      <th>ESO4_ECl_ENO3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23499</td>\n",
       "      <td>1984</td>\n",
       "      <td>884.5</td>\n",
       "      <td>4.05</td>\n",
       "      <td>138.750000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>52.083333</td>\n",
       "      <td>53.25</td>\n",
       "      <td>68.857143</td>\n",
       "      <td>136.072000</td>\n",
       "      <td>46.987333</td>\n",
       "      <td>52.288000</td>\n",
       "      <td>164.750000</td>\n",
       "      <td>105.333333</td>\n",
       "      <td>99.275333</td>\n",
       "      <td>233.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23499</td>\n",
       "      <td>1985</td>\n",
       "      <td>851.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142.708333</td>\n",
       "      <td>25.428571</td>\n",
       "      <td>48.333333</td>\n",
       "      <td>50.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.089190</td>\n",
       "      <td>43.349333</td>\n",
       "      <td>49.559143</td>\n",
       "      <td>168.136905</td>\n",
       "      <td>98.833333</td>\n",
       "      <td>92.908476</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23499</td>\n",
       "      <td>1986</td>\n",
       "      <td>856.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143.541667</td>\n",
       "      <td>29.428571</td>\n",
       "      <td>45.833333</td>\n",
       "      <td>52.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.510524</td>\n",
       "      <td>40.065333</td>\n",
       "      <td>50.911143</td>\n",
       "      <td>172.970238</td>\n",
       "      <td>97.833333</td>\n",
       "      <td>90.976476</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23499</td>\n",
       "      <td>1987</td>\n",
       "      <td>750.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137.916667</td>\n",
       "      <td>29.428571</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>55.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>134.885524</td>\n",
       "      <td>39.232000</td>\n",
       "      <td>53.911143</td>\n",
       "      <td>167.345238</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>93.143143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23499</td>\n",
       "      <td>1988</td>\n",
       "      <td>795.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.562500</td>\n",
       "      <td>22.571429</td>\n",
       "      <td>46.250000</td>\n",
       "      <td>50.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124.237643</td>\n",
       "      <td>41.826000</td>\n",
       "      <td>49.664857</td>\n",
       "      <td>149.133929</td>\n",
       "      <td>96.750000</td>\n",
       "      <td>91.490857</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id  year     Al   TOC        ESO4        ECl        EMg    ECa  \\\n",
       "0       23499  1984  884.5  4.05  138.750000  26.000000  52.083333  53.25   \n",
       "1       23499  1985  851.0   NaN  142.708333  25.428571  48.333333  50.50   \n",
       "2       23499  1986  856.5   NaN  143.541667  29.428571  45.833333  52.00   \n",
       "3       23499  1987  750.0   NaN  137.916667  29.428571  45.000000  55.00   \n",
       "4       23499  1988  795.0   NaN  126.562500  22.571429  46.250000  50.50   \n",
       "\n",
       "        ENO3       ESO4X       EMgX       ECaX    ESO4_ECl     ECa_EMg  \\\n",
       "0  68.857143  136.072000  46.987333  52.288000  164.750000  105.333333   \n",
       "1        NaN  140.089190  43.349333  49.559143  168.136905   98.833333   \n",
       "2        NaN  140.510524  40.065333  50.911143  172.970238   97.833333   \n",
       "3        NaN  134.885524  39.232000  53.911143  167.345238  100.000000   \n",
       "4        NaN  124.237643  41.826000  49.664857  149.133929   96.750000   \n",
       "\n",
       "   ECaX_EMgX  ESO4_ECl_ENO3  \n",
       "0  99.275333     233.607143  \n",
       "1  92.908476            NaN  \n",
       "2  90.976476            NaN  \n",
       "3  93.143143            NaN  \n",
       "4  91.490857            NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Convert to ueq/l\n",
    "for par in ['SO4', 'Cl', 'Mg', 'Ca', 'NO3-N']:\n",
    "    val = chem_df.ix[par, 'valency']\n",
    "    mm = chem_df.ix[par, 'molar_mass']\n",
    "    \n",
    "    if par == 'NO3-N':\n",
    "        wc_df['ENO3'] = wc_df[par] * val / mm\n",
    "    else:\n",
    "        wc_df['E%s' % par] = wc_df[par] * val * 1000. / mm\n",
    "\n",
    "# 2. Apply sea-salt correction\n",
    "for par in ['ESO4', 'EMg', 'ECa']:\n",
    "    ref = chem_df.ix[par[1:], 'resa2_ref_ratio']\n",
    "    wc_df['%sX' % par] = wc_df[par] - (ref*wc_df['ECl'])\n",
    "    \n",
    "# 3. Calculate combinations\n",
    "# 3.1. ESO4 + ECl\n",
    "wc_df['ESO4_ECl'] = wc_df['ESO4'] + wc_df['ECl']\n",
    "\n",
    "# 3.2. ECa + EMg\n",
    "wc_df['ECa_EMg'] = wc_df['ECa'] + wc_df['EMg']\n",
    "\n",
    "# 3.3. ECaX + EMgX\n",
    "wc_df['ECaX_EMgX'] = wc_df['ECaX'] + wc_df['EMgX']\n",
    "\n",
    "# 3.4. ESO4 + ECl + ENO3\n",
    "wc_df['ESO4_ECl_ENO3'] = wc_df['ESO4'] + wc_df['ECl'] + wc_df['ENO3']\n",
    "\n",
    "# 4. Delete unnecessary columns and tidy\n",
    "for col in ['SO4', 'Cl', 'Mg', 'Ca', 'NO3-N']:\n",
    "    del wc_df[col]\n",
    "\n",
    "wc_df.reset_index(inplace=True)\n",
    "    \n",
    "wc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Calculate trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>par_id</th>\n",
       "      <th>period</th>\n",
       "      <th>non_missing</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>mk_stat</th>\n",
       "      <th>norm_mk_stat</th>\n",
       "      <th>mk_p_val</th>\n",
       "      <th>mk_std_dev</th>\n",
       "      <th>trend</th>\n",
       "      <th>sen_slp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23499</td>\n",
       "      <td>Al</td>\n",
       "      <td>1984-2014</td>\n",
       "      <td>31</td>\n",
       "      <td>493.670533</td>\n",
       "      <td>487.500000</td>\n",
       "      <td>217.901691</td>\n",
       "      <td>-341.0</td>\n",
       "      <td>-5.778782</td>\n",
       "      <td>7.524345e-09</td>\n",
       "      <td>58.835930</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23499</td>\n",
       "      <td>TOC</td>\n",
       "      <td>1984-2014</td>\n",
       "      <td>22</td>\n",
       "      <td>1.953409</td>\n",
       "      <td>1.775000</td>\n",
       "      <td>0.744290</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.833595</td>\n",
       "      <td>6.671420e-02</td>\n",
       "      <td>35.449495</td>\n",
       "      <td>no trend</td>\n",
       "      <td>0.043750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23499</td>\n",
       "      <td>ESO4</td>\n",
       "      <td>1984-2014</td>\n",
       "      <td>31</td>\n",
       "      <td>90.795274</td>\n",
       "      <td>88.020833</td>\n",
       "      <td>32.177584</td>\n",
       "      <td>-429.0</td>\n",
       "      <td>-7.274466</td>\n",
       "      <td>3.477219e-13</td>\n",
       "      <td>58.835930</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-3.523551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23499</td>\n",
       "      <td>ECl</td>\n",
       "      <td>1984-2014</td>\n",
       "      <td>31</td>\n",
       "      <td>20.778903</td>\n",
       "      <td>21.142857</td>\n",
       "      <td>4.846152</td>\n",
       "      <td>-311.0</td>\n",
       "      <td>-5.270412</td>\n",
       "      <td>1.361179e-07</td>\n",
       "      <td>58.818931</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-0.441558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23499</td>\n",
       "      <td>EMg</td>\n",
       "      <td>1984-2014</td>\n",
       "      <td>31</td>\n",
       "      <td>39.522452</td>\n",
       "      <td>38.750000</td>\n",
       "      <td>5.930091</td>\n",
       "      <td>-355.0</td>\n",
       "      <td>-6.022534</td>\n",
       "      <td>1.717076e-09</td>\n",
       "      <td>58.779248</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-0.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id par_id     period  non_missing        mean      median  \\\n",
       "0       23499     Al  1984-2014           31  493.670533  487.500000   \n",
       "1       23499    TOC  1984-2014           22    1.953409    1.775000   \n",
       "2       23499   ESO4  1984-2014           31   90.795274   88.020833   \n",
       "3       23499    ECl  1984-2014           31   20.778903   21.142857   \n",
       "4       23499    EMg  1984-2014           31   39.522452   38.750000   \n",
       "\n",
       "      std_dev  mk_stat  norm_mk_stat      mk_p_val  mk_std_dev       trend  \\\n",
       "0  217.901691   -341.0     -5.778782  7.524345e-09   58.835930  decreasing   \n",
       "1    0.744290     66.0      1.833595  6.671420e-02   35.449495    no trend   \n",
       "2   32.177584   -429.0     -7.274466  3.477219e-13   58.835930  decreasing   \n",
       "3    4.846152   -311.0     -5.270412  1.361179e-07   58.818931  decreasing   \n",
       "4    5.930091   -355.0     -6.022534  1.717076e-09   58.779248  decreasing   \n",
       "\n",
       "     sen_slp  \n",
       "0 -21.000000  \n",
       "1   0.043750  \n",
       "2  -3.523551  \n",
       "3  -0.441558  \n",
       "4  -0.583333  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_water_chem_df(stn_df, wc_df, st_yr=None, end_yr=None):\n",
    "    \"\"\" Calculate statistics for the stations, parameters and time\n",
    "        periods specified.\n",
    "    \n",
    "    Args:\n",
    "        stn_df:   Dataframe of station_ids\n",
    "        wc_df:    Dataframe of water chemistry time series for stations\n",
    "                  and parameters of interest\n",
    "        st_yr:    First year to include in analysis. Pass None to start\n",
    "                  at the beginning of the series\n",
    "        end_year: Last year to include in analysis. Pass None to start\n",
    "                  at the beginning of the series\n",
    "    \n",
    "    Returns:\n",
    "        Dataframe of statistics\n",
    "    \"\"\"\n",
    "    # Container for output\n",
    "    df_list = []\n",
    "\n",
    "    # Loop over sites\n",
    "    for stn_id in stn_df['station_id']:\n",
    "        # Extract data for this site\n",
    "        df = wc_df.query('station_id == @stn_id')\n",
    "\n",
    "        # Modify col names\n",
    "        names = list(df.columns)\n",
    "        names[:2] = ['STATION_ID', 'YEAR']\n",
    "        df.columns = names\n",
    "\n",
    "        # Run analysis\n",
    "        df_list.append(toc_stats(df, st_yr=st_yr, end_yr=end_yr))\n",
    "\n",
    "    res_df = pd.concat(df_list, axis=0)\n",
    "    \n",
    "    return res_df\n",
    "    \n",
    "res_df = process_water_chem_df(stn_df, wc_df)\n",
    "\n",
    "res_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare to previous trends analysis\n",
    "\n",
    "This seems to be working OK so far, but I need to do some more testing to see that my results more-or-less agree with those calculated previously by Tore. As a start, let's compare the results above with those in the `ICPW_STATISTICS3` table of RESA2, which is where (I think) Tore has saved his previous output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>parameter</th>\n",
       "      <th>period</th>\n",
       "      <th>nonmiss</th>\n",
       "      <th>average</th>\n",
       "      <th>median</th>\n",
       "      <th>stdev</th>\n",
       "      <th>test_stat</th>\n",
       "      <th>mk_stat</th>\n",
       "      <th>mkp</th>\n",
       "      <th>senslope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23499</td>\n",
       "      <td>AL</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>486.052433</td>\n",
       "      <td>503.500000</td>\n",
       "      <td>186.876929</td>\n",
       "      <td>-83</td>\n",
       "      <td>-4.107435</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>-32.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23499</td>\n",
       "      <td>ALK</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>14</td>\n",
       "      <td>-15.896429</td>\n",
       "      <td>-15.850000</td>\n",
       "      <td>6.270918</td>\n",
       "      <td>20</td>\n",
       "      <td>1.096542</td>\n",
       "      <td>0.272842</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23499</td>\n",
       "      <td>ANC</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>12</td>\n",
       "      <td>-47.948231</td>\n",
       "      <td>-53.510865</td>\n",
       "      <td>14.813228</td>\n",
       "      <td>48</td>\n",
       "      <td>3.291482</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>3.178531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23499</td>\n",
       "      <td>ECAEMG</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>84.136540</td>\n",
       "      <td>83.398845</td>\n",
       "      <td>9.581870</td>\n",
       "      <td>-75</td>\n",
       "      <td>-3.711537</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>-1.968997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23499</td>\n",
       "      <td>ECAXEMGX</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>79.221717</td>\n",
       "      <td>78.338350</td>\n",
       "      <td>9.248877</td>\n",
       "      <td>-71</td>\n",
       "      <td>-3.513589</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>-1.886138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23499</td>\n",
       "      <td>ECL</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>21.093655</td>\n",
       "      <td>21.718895</td>\n",
       "      <td>2.980660</td>\n",
       "      <td>-44</td>\n",
       "      <td>-2.180106</td>\n",
       "      <td>0.029250</td>\n",
       "      <td>-0.435917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23499</td>\n",
       "      <td>ENO3</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>12</td>\n",
       "      <td>65.111360</td>\n",
       "      <td>66.036608</td>\n",
       "      <td>7.299949</td>\n",
       "      <td>-40</td>\n",
       "      <td>-2.742902</td>\n",
       "      <td>0.006090</td>\n",
       "      <td>-1.234397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>23499</td>\n",
       "      <td>ENO3DIVENO3ESO4X</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>12</td>\n",
       "      <td>0.428599</td>\n",
       "      <td>0.427500</td>\n",
       "      <td>0.028221</td>\n",
       "      <td>32</td>\n",
       "      <td>2.194322</td>\n",
       "      <td>0.028212</td>\n",
       "      <td>0.006281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23499</td>\n",
       "      <td>ESO4</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>95.643491</td>\n",
       "      <td>97.541580</td>\n",
       "      <td>18.305102</td>\n",
       "      <td>-97</td>\n",
       "      <td>-4.800255</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-4.089638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23499</td>\n",
       "      <td>ESO4CL</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>116.737145</td>\n",
       "      <td>118.934785</td>\n",
       "      <td>20.274570</td>\n",
       "      <td>-95</td>\n",
       "      <td>-4.701281</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-4.449103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>23499</td>\n",
       "      <td>ESO4ECLENO3</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>12</td>\n",
       "      <td>175.508512</td>\n",
       "      <td>176.306256</td>\n",
       "      <td>23.280313</td>\n",
       "      <td>-52</td>\n",
       "      <td>-3.565772</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>-5.589727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23499</td>\n",
       "      <td>ESO4X</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>93.470844</td>\n",
       "      <td>95.253690</td>\n",
       "      <td>18.117947</td>\n",
       "      <td>-97</td>\n",
       "      <td>-4.800255</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-4.033607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23499</td>\n",
       "      <td>HPLUSS</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>18.383278</td>\n",
       "      <td>18.506625</td>\n",
       "      <td>4.313829</td>\n",
       "      <td>-69</td>\n",
       "      <td>-3.414614</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>-0.795074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23499</td>\n",
       "      <td>TOC_DOC</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>11</td>\n",
       "      <td>1.561364</td>\n",
       "      <td>1.385000</td>\n",
       "      <td>0.554342</td>\n",
       "      <td>4</td>\n",
       "      <td>0.312348</td>\n",
       "      <td>0.754776</td>\n",
       "      <td>0.009286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    station_id         parameter     period  nonmiss     average      median  \\\n",
       "8        23499                AL  1990-2004       15  486.052433  503.500000   \n",
       "10       23499               ALK  1990-2004       14  -15.896429  -15.850000   \n",
       "9        23499               ANC  1990-2004       12  -47.948231  -53.510865   \n",
       "5        23499            ECAEMG  1990-2004       15   84.136540   83.398845   \n",
       "6        23499          ECAXEMGX  1990-2004       15   79.221717   78.338350   \n",
       "2        23499               ECL  1990-2004       15   21.093655   21.718895   \n",
       "7        23499              ENO3  1990-2004       12   65.111360   66.036608   \n",
       "13       23499  ENO3DIVENO3ESO4X  1990-2004       12    0.428599    0.427500   \n",
       "0        23499              ESO4  1990-2004       15   95.643491   97.541580   \n",
       "3        23499            ESO4CL  1990-2004       15  116.737145  118.934785   \n",
       "12       23499       ESO4ECLENO3  1990-2004       12  175.508512  176.306256   \n",
       "1        23499             ESO4X  1990-2004       15   93.470844   95.253690   \n",
       "11       23499            HPLUSS  1990-2004       15   18.383278   18.506625   \n",
       "4        23499           TOC_DOC  1990-2004       11    1.561364    1.385000   \n",
       "\n",
       "         stdev  test_stat   mk_stat       mkp   senslope  \n",
       "8   186.876929        -83 -4.107435  0.000040 -32.700000  \n",
       "10    6.270918         20  1.096542  0.272842   0.500000  \n",
       "9    14.813228         48  3.291482  0.000997   3.178531  \n",
       "5     9.581870        -75 -3.711537  0.000206  -1.968997  \n",
       "6     9.248877        -71 -3.513589  0.000442  -1.886138  \n",
       "2     2.980660        -44 -2.180106  0.029250  -0.435917  \n",
       "7     7.299949        -40 -2.742902  0.006090  -1.234397  \n",
       "13    0.028221         32  2.194322  0.028212   0.006281  \n",
       "0    18.305102        -97 -4.800255  0.000002  -4.089638  \n",
       "3    20.274570        -95 -4.701281  0.000003  -4.449103  \n",
       "12   23.280313        -52 -3.565772  0.000363  -5.589727  \n",
       "1    18.117947        -97 -4.800255  0.000002  -4.033607  \n",
       "11    4.313829        -69 -3.414614  0.000639  -0.795074  \n",
       "4     0.554342          4  0.312348  0.754776   0.009286  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get results for test sites from RESA2\n",
    "sql = ('SELECT * FROM resa2.icpw_statistics3 '\n",
    "       'WHERE station_id IN %s' \n",
    "       % str(tuple(stn_df['station_id'].values)))\n",
    "\n",
    "stat_df = pd.read_sql(sql, engine)\n",
    "\n",
    "# Get just the cols to compare to my output\n",
    "stat_df = stat_df[['station_id', 'parameter', 'period', 'nonmiss',\n",
    "                   'average', 'median', 'stdev', 'test_stat', \n",
    "                   'mk_stat', 'mkp', 'senslope']]\n",
    "\n",
    "stat_df.head(14).sort_values(by='parameter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For e.g. site 23499, I can now re-run my code for the period from 1990 to 2004 and compare my results to those above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>par_id</th>\n",
       "      <th>period</th>\n",
       "      <th>non_missing</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>mk_stat</th>\n",
       "      <th>norm_mk_stat</th>\n",
       "      <th>mk_p_val</th>\n",
       "      <th>trend</th>\n",
       "      <th>sen_slp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23499</td>\n",
       "      <td>Al</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>485.085767</td>\n",
       "      <td>503.500000</td>\n",
       "      <td>187.586374</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>-4.057948</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-33.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23499</td>\n",
       "      <td>ECa</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>44.283333</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>5.584470</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-3.662050</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-1.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23499</td>\n",
       "      <td>ECaX</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>43.489771</td>\n",
       "      <td>43.186000</td>\n",
       "      <td>5.524900</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-3.662050</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-1.179175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>23499</td>\n",
       "      <td>ECaX_EMgX</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>79.786038</td>\n",
       "      <td>78.874000</td>\n",
       "      <td>9.366281</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-3.464102</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-1.899667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23499</td>\n",
       "      <td>ECa_EMg</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>84.783333</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>9.708540</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>-3.563076</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-1.981481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23499</td>\n",
       "      <td>ECl</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>21.447619</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.017861</td>\n",
       "      <td>-44.0</td>\n",
       "      <td>-2.130559</td>\n",
       "      <td>0.033126</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-0.441558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23499</td>\n",
       "      <td>EMg</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>4.170237</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-3.671052</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23499</td>\n",
       "      <td>EMgX</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>36.296267</td>\n",
       "      <td>35.930000</td>\n",
       "      <td>3.924888</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>-3.266153</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-0.739152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23499</td>\n",
       "      <td>ENO3</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>12</td>\n",
       "      <td>64.866071</td>\n",
       "      <td>66.037500</td>\n",
       "      <td>7.380028</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>-2.674329</td>\n",
       "      <td>0.007488</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-1.278393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23499</td>\n",
       "      <td>ESO4</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>95.625000</td>\n",
       "      <td>98.125000</td>\n",
       "      <td>18.527533</td>\n",
       "      <td>-95.0</td>\n",
       "      <td>-4.651794</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-4.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23499</td>\n",
       "      <td>ESO4X</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>93.415895</td>\n",
       "      <td>95.947286</td>\n",
       "      <td>18.336954</td>\n",
       "      <td>-95.0</td>\n",
       "      <td>-4.651794</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-3.965619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23499</td>\n",
       "      <td>ESO4_ECl</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>117.072619</td>\n",
       "      <td>119.267857</td>\n",
       "      <td>20.531061</td>\n",
       "      <td>-95.0</td>\n",
       "      <td>-4.651794</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-4.457792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>23499</td>\n",
       "      <td>ESO4_ECl_ENO3</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>12</td>\n",
       "      <td>175.649554</td>\n",
       "      <td>176.662202</td>\n",
       "      <td>23.824901</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>-3.360055</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-5.648674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23499</td>\n",
       "      <td>TOC</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>11</td>\n",
       "      <td>1.561364</td>\n",
       "      <td>1.385000</td>\n",
       "      <td>0.554342</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.234261</td>\n",
       "      <td>0.814783</td>\n",
       "      <td>no trend</td>\n",
       "      <td>0.009286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    station_id         par_id     period  non_missing        mean      median  \\\n",
       "0        23499             Al  1990-2004           15  485.085767  503.500000   \n",
       "5        23499            ECa  1990-2004           15   44.283333   44.000000   \n",
       "9        23499           ECaX  1990-2004           15   43.489771   43.186000   \n",
       "12       23499      ECaX_EMgX  1990-2004           15   79.786038   78.874000   \n",
       "11       23499        ECa_EMg  1990-2004           15   84.783333   84.000000   \n",
       "3        23499            ECl  1990-2004           15   21.447619   22.000000   \n",
       "4        23499            EMg  1990-2004           15   40.500000   40.000000   \n",
       "8        23499           EMgX  1990-2004           15   36.296267   35.930000   \n",
       "6        23499           ENO3  1990-2004           12   64.866071   66.037500   \n",
       "2        23499           ESO4  1990-2004           15   95.625000   98.125000   \n",
       "7        23499          ESO4X  1990-2004           15   93.415895   95.947286   \n",
       "10       23499       ESO4_ECl  1990-2004           15  117.072619  119.267857   \n",
       "13       23499  ESO4_ECl_ENO3  1990-2004           12  175.649554  176.662202   \n",
       "1        23499            TOC  1990-2004           11    1.561364    1.385000   \n",
       "\n",
       "       std_dev  mk_stat  norm_mk_stat  mk_p_val       trend    sen_slp  \n",
       "0   187.586374    -83.0     -4.057948  0.000050  decreasing -33.200000  \n",
       "5     5.584470    -75.0     -3.662050  0.000250  decreasing  -1.166667  \n",
       "9     5.524900    -75.0     -3.662050  0.000250  decreasing  -1.179175  \n",
       "12    9.366281    -71.0     -3.464102  0.000532  decreasing  -1.899667  \n",
       "11    9.708540    -73.0     -3.563076  0.000367  decreasing  -1.981481  \n",
       "3     3.017861    -44.0     -2.130559  0.033126  decreasing  -0.441558  \n",
       "4     4.170237    -75.0     -3.671052  0.000242  decreasing  -0.833333  \n",
       "8     3.924888    -67.0     -3.266153  0.001090  decreasing  -0.739152  \n",
       "6     7.380028    -40.0     -2.674329  0.007488  decreasing  -1.278393  \n",
       "2    18.527533    -95.0     -4.651794  0.000003  decreasing  -4.083333  \n",
       "7    18.336954    -95.0     -4.651794  0.000003  decreasing  -3.965619  \n",
       "10   20.531061    -95.0     -4.651794  0.000003  decreasing  -4.457792  \n",
       "13   23.824901    -50.0     -3.360055  0.000779  decreasing  -5.648674  \n",
       "1     0.554342      4.0      0.234261  0.814783    no trend   0.009286  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-run python analysis for the period 1990 - 2004\n",
    "res_df = process_water_chem_df(stn_df, wc_df, st_yr=1990, end_yr=2004)\n",
    "\n",
    "# Delete mk_std_dev as not relevant here\n",
    "del res_df['mk_std_dev']\n",
    "\n",
    "res_df.head(14).sort_values(by='par_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The numbers in the above two tables are *almost* identical**, which is actually pretty remarkable given that I'm second-guessing a lot of the decisions in Tore's analysis (having never seen his code) and also recoding everything from scratch. It certainly looks as though this will be a viable alternative for re-running the trends analysis.\n",
    "\n",
    "There are still some loose ends to tie up. In particular, I need to add a few more parameters to the trends calculation, but that shouldn't be difficult once I've spoken to Heleen to find out what they are and how to calculate them. In the meantime, I'm sufficiently happy with this output to move the code into a separate module and then continue to explore the data in a new notebook.\n",
    "\n",
    "**NB:** A nice way to visualise these results would be to create a google map, where each point is coloured according to 'increasing', 'decreasing' or 'no trend'. A pop-up on each point could then give the main summary statistics and a time series plot with the Sen's slope line overlaid. This would result in lots of points on top on each other, but users could filter the map to just show one parameter at a time to avoid things becoming too cluttered. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
