{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt, seaborn as sn, mpld3\n",
    "import pandas as pd, imp, glob, os\n",
    "from sqlalchemy import create_engine\n",
    "sn.set_context('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated TOC trends analysis (part 2)\n",
    "\n",
    "This notebook begins to explore trends in the broader water chemistry dataset collated by Heleen, Don and John for the updated TOC analysis. Note that **the results presented here should be considered preliminary as there are still some outstanding database \"cleaning\" tasks that I haven't found time for yet**. The reason I'm jumping ahead of myself here is because I suspect the best way to identify any further data issues is to attempt the trend analysis and see what problems crop up.\n",
    "\n",
    "My original plan - as agreed with Heleen, Don and John in May - was to tidy up the data as much as possible and then simply re-run Tore's code for the trends calculations. Unfortunately, although I've managed to find most of the necessary code (either within RESA2 or as VBA projects within linked Access databases), I have been unable to locate some of the crucial subroutines, including the ones for the bulk of the statistical analysis. In addition, as far as I can tell, the code relies on an old, third-party Excel macro for the statistical calculations, and using this involves a lot of data shuffling (first from RESA2 to Excel, then into Access and finally back into RESA2), which is quite slow and difficult to keep track of.\n",
    "\n",
    "What I *have* found in RESA2 is a table called `ICPW_STATISTICS3`, which appears to store the output of Tore's analysis. I think my best option is therefore to recode the whole thing from scratch, and then compare my results with those in Tore's table to make sure what I'm doing is more-or-less compatible with what's been done before. This will involve digging into the internlas of RESA2, which will hopefuily be a good learning experience for me as well.\n",
    "\n",
    "## 1. Trend analysis code\n",
    "\n",
    "This section provides an overview of the code I've written for the updated trends analysis. The code was initially developed in an [earlier iPython notebook](http://nbviewer.jupyter.org/url/www.googledrive.com/host/0BximeC_RweaeUy1jd2k3Nm1kdms/updated_toc_trends_analysis.ipynb) and later moved into a `.py` file to allow the trends functionality to be imported into other notebooks. This Python file is here:\n",
    "\n",
    "C:\\Data\\James_Work\\Staff\\Heleen_d_W\\ICP_Waters\\TOC_Trends_Analysis_2015\\Python\\toc_trends_analysis.py\n",
    "\n",
    "**NB:** The code in the Python file is slightly different and more sophisticated than in the original notebook. **Use the Python file (not the notebook) as the basis for any further developments**.\n",
    "\n",
    "To run an analysis, the user must provide a list of valid RESA2 **project names**, plus start and end years for the period of interest. Optionally, it is possible to specify a folder where trend plots for each parameter will be stored. The code then performs the following operations:\n",
    "\n",
    " 1. Identifies all the monitoring stations associated with the specified projects. <br><br>\n",
    " \n",
    " 2. Generates a list of water samples and sampling dates for all these stations within the period of interest. If some stations have no samples within the specified period, a **warning message** is printed and the list of stations with no data is included in the output. \n",
    "    \n",
    "    Note that RESA2 sometimes includes measurements for samples collected at several different water depths. The code currently only selects **near-surface water samples** (depth $\\leq 1 \\; m$). **Check this with Heleen**. <br><br>\n",
    " \n",
    " 3. Extracts the data for the key trends parameters (currently `'SO4', 'Cl', 'Ca', 'Mg', 'NO3-N', 'TOC'` and `'Al'`, but this need amending - see below) for the selected water samples and converts the raw values from the units and methods originally specified into the RESA2's \"standard\" units (as specified in the `RESA2.PARAMETER_DEFINITIONS` table). <br><br>\n",
    " \n",
    " 4. Checks for duplicate measurements of the same parameter at the same sampling point and date. If duplicates are found, the values are **averaged** and a **warning message** is printed. A list of duplicated records is then included in the output to facilitate data checking.  <br><br>\n",
    " \n",
    " 5. Sampled values are aggregated from the native data collection interval to **annual frequency** by taking **medians**.  <br><br>\n",
    " \n",
    " 6. For the parameters `'SO4', 'Cl', 'Mg', 'Ca'` and `'NO3-N'`, concentrations are recalculated as $\\mu eq/l$ (denoted by the prefix 'E' e.g. ESO4).\n",
    " \n",
    " $$EPAR \\; (\\mu eq/l) = \\frac{1.10^6 * valency}{molar \\; mass \\; (g/mol)} * PAR \\; (g/l)$$ <br><br>\n",
    " \n",
    " 7. Sea-salt corrections are then applied for the parameters `'ESO4', 'EMg'` and `'ECa']` (denoted by the suffix 'X' e.g. ESO4X). \n",
    " \n",
    " $$EPARX = EPAR_{sample} - \\left[ \\left( \\frac{EPAR}{ECl} \\right)_{ref} * ECl_{sample} \\right]$$\n",
    "\n",
    "    **NB:** I'm not sure what reference ratios were used in the original analysis. I've attempted to back-calculate them from RESA2, and it looks as though a single value has been assumed worldwide for each parameter? **Check this with Heleen**. Also, **see section 4.1.2 of the [code development notebook](http://nbviewer.jupyter.org/url/www.googledrive.com/host/0BximeC_RweaeUy1jd2k3Nm1kdms/updated_toc_trends_analysis.ipynb) for more details**. <br><br>\n",
    "    \n",
    " 8. Calculates **combined parameters** e.g. `ESO4_ECl` is calculated as $(ESO4 + ECl)$ etc.\n",
    " \n",
    "    At present, the code generates annual time series for the following parameters:\n",
    "    \n",
    "      * `ESO4` ($\\mu eq/l$)\n",
    "      * `ESO4X` ($\\mu eq/l$)\n",
    "      * `ECl` ($\\mu eq/l$)\n",
    "      * `ESO4_ECl` ($\\mu eq/l$)\n",
    "      * `ECa_EMg` ($\\mu eq/l$)\n",
    "      * `ECaX_EMgX` ($\\mu eq/l$)\n",
    "      * `ENO3` ($\\mu eq/l$)\n",
    "      * `ESO4_ECl_ENO3` ($\\mu eq/l$)\n",
    "      * `TOC` ($mg C/l$)\n",
    "      * `Al` ($mg/l$)\n",
    "\n",
    "    **NB:** It looks as though Tore's code calculates a few additional parameters as well:\n",
    "    \n",
    "      * `ANC`\n",
    "      * `ALK`\n",
    "      * `HPLUS`\n",
    "      * `ENO3_DIV_ENO3_ESO4X`\n",
    "    \n",
    "    These will be easy to add, but I'd like to check exactly **which parameters are of interest and how they should be calculated** before including them. <br><br>\n",
    "    \n",
    " 9. Performs statistical analysis for each parameter at each site for the period specified. The output includes the following summary statistics:\n",
    "\n",
    "    * Period over which data are available (i.e. start and end years, which are not always the same as the period originally specified)\n",
    "    * Number of non-missing values\n",
    "    * Median of data values\n",
    "    * Mean of data values\n",
    "    * Standard deviation of data values\n",
    "    * Standard deviation expected under the null hypothesis of the [Mann-Kendall (M-K) test](https://cran.r-project.org/web/packages/trend/vignettes/trend.pdf)\n",
    "    * M-K statistic\n",
    "    * Normalised M-K statistic $\\left(= \\frac{M-K \\; statistic}{Expected \\; standard \\; deviation} \\right)$\n",
    "    * M-K p-value\n",
    "    * Sen's slope (a.k.a. the [Theil-Sen slope](https://en.wikipedia.org/wiki/Theil%E2%80%93Sen_estimator)). Optionally, a plot of the trend line can be produced.\n",
    "\n",
    "    Note that the algorithm uses the [normal approximation](http://vsp.pnnl.gov/help/Vsample/Design_Trend_Mann_Kendall.htm) to estimate the variance of the `S` parameter in the M-K test (and thereby the significance of any trends). This approximation is only robust when the number of non-null data points in the time series is $\\geq 10$. If the number of non-missing values is fewer than 10, the code prints a **warning message** to indicate significance estimates may be unreliable.  <br><br>\n",
    "    \n",
    " 10. The output from the algorithm consists of (i) **a dataframe of summary statistics** for each parameter at each site over the period of interest; (ii) **a list of stations with no data** in the period specified and (iii) **a list of duplicated values** (where the database contains two measurements of the same parameter at the same location on the same day). If the `plot` option is set to `True` when the function is called, the code will also output (iv) **plots of the Theil-Sen regression line** for each parameter, saved to the specified output folder.\n",
    " \n",
    "## 2. Illustrative example and testing\n",
    "\n",
    "This section illustrates how the code can be used to estimate trends. As a basic test, I'll start by reading some results from Tore's `ICPW_STATISTICS3` table, which I believe stores the output from his statistical analyses. I'll then run my code for the same stations and time periods to make sure the results are comparable.\n",
    "\n",
    "**NB:** My [earlier notebook](http://nbviewer.jupyter.org/url/www.googledrive.com/host/0BximeC_RweaeUy1jd2k3Nm1kdms/updated_toc_trends_analysis.ipynb) focussing on the code development includes some more rigorous testing.\n",
    "\n",
    "### 2.1. Import modules and connect to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import custom functions\n",
    "# Connect to db\n",
    "resa2_basic_path = (r'C:\\Data\\James_Work\\Staff\\Heleen_d_W\\ICP_Waters\\Upload_Template'\n",
    "                    r'\\useful_resa2_code.py')\n",
    "\n",
    "resa2_basic = imp.load_source('useful_resa2_code', resa2_basic_path)\n",
    "\n",
    "engine, conn = resa2_basic.connect_to_resa2()\n",
    "\n",
    "# Import code for trends analysis\n",
    "resa2_trends_path = (r'C:\\Data\\James_Work\\Staff\\Heleen_d_W\\ICP_Waters\\TOC_Trends_Analysis_2015'\n",
    "                     r'\\Python\\toc_trends_analysis.py')\n",
    "\n",
    "resa2_trends = imp.load_source('toc_trends_analysis', resa2_trends_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Read previous results from RESA2\n",
    "\n",
    "As an example, we'll extract some of Tore's results for one of the Czech sites (`station_id = 23499`) for the period from 1990 to 2004."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>parameter</th>\n",
       "      <th>period</th>\n",
       "      <th>nonmiss</th>\n",
       "      <th>average</th>\n",
       "      <th>median</th>\n",
       "      <th>stdev</th>\n",
       "      <th>test_stat</th>\n",
       "      <th>mk_stat</th>\n",
       "      <th>mkp</th>\n",
       "      <th>senslope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23499</td>\n",
       "      <td>AL</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>486.052433</td>\n",
       "      <td>503.500000</td>\n",
       "      <td>186.876929</td>\n",
       "      <td>-83</td>\n",
       "      <td>-4.107435</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>-32.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23499</td>\n",
       "      <td>ALK</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>14</td>\n",
       "      <td>-15.896429</td>\n",
       "      <td>-15.850000</td>\n",
       "      <td>6.270918</td>\n",
       "      <td>20</td>\n",
       "      <td>1.096542</td>\n",
       "      <td>0.272842</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23499</td>\n",
       "      <td>ANC</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>12</td>\n",
       "      <td>-47.948231</td>\n",
       "      <td>-53.510865</td>\n",
       "      <td>14.813228</td>\n",
       "      <td>48</td>\n",
       "      <td>3.291482</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>3.178531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23499</td>\n",
       "      <td>ECAEMG</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>84.136540</td>\n",
       "      <td>83.398845</td>\n",
       "      <td>9.581870</td>\n",
       "      <td>-75</td>\n",
       "      <td>-3.711537</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>-1.968997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23499</td>\n",
       "      <td>ECAXEMGX</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>79.221717</td>\n",
       "      <td>78.338350</td>\n",
       "      <td>9.248877</td>\n",
       "      <td>-71</td>\n",
       "      <td>-3.513589</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>-1.886138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23499</td>\n",
       "      <td>ECL</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>21.093655</td>\n",
       "      <td>21.718895</td>\n",
       "      <td>2.980660</td>\n",
       "      <td>-44</td>\n",
       "      <td>-2.180106</td>\n",
       "      <td>0.029250</td>\n",
       "      <td>-0.435917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23499</td>\n",
       "      <td>ENO3</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>12</td>\n",
       "      <td>65.111360</td>\n",
       "      <td>66.036608</td>\n",
       "      <td>7.299949</td>\n",
       "      <td>-40</td>\n",
       "      <td>-2.742902</td>\n",
       "      <td>0.006090</td>\n",
       "      <td>-1.234397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23499</td>\n",
       "      <td>ENO3DIVENO3ESO4X</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>12</td>\n",
       "      <td>0.428599</td>\n",
       "      <td>0.427500</td>\n",
       "      <td>0.028221</td>\n",
       "      <td>32</td>\n",
       "      <td>2.194322</td>\n",
       "      <td>0.028212</td>\n",
       "      <td>0.006281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23499</td>\n",
       "      <td>ESO4</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>95.643491</td>\n",
       "      <td>97.541580</td>\n",
       "      <td>18.305102</td>\n",
       "      <td>-97</td>\n",
       "      <td>-4.800255</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-4.089638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23499</td>\n",
       "      <td>ESO4CL</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>116.737145</td>\n",
       "      <td>118.934785</td>\n",
       "      <td>20.274570</td>\n",
       "      <td>-95</td>\n",
       "      <td>-4.701281</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-4.449103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23499</td>\n",
       "      <td>ESO4ECLENO3</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>12</td>\n",
       "      <td>175.508512</td>\n",
       "      <td>176.306256</td>\n",
       "      <td>23.280313</td>\n",
       "      <td>-52</td>\n",
       "      <td>-3.565772</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>-5.589727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23499</td>\n",
       "      <td>ESO4X</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>93.470844</td>\n",
       "      <td>95.253690</td>\n",
       "      <td>18.117947</td>\n",
       "      <td>-97</td>\n",
       "      <td>-4.800255</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-4.033607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>23499</td>\n",
       "      <td>HPLUSS</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>18.383278</td>\n",
       "      <td>18.506625</td>\n",
       "      <td>4.313829</td>\n",
       "      <td>-69</td>\n",
       "      <td>-3.414614</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>-0.795074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>23499</td>\n",
       "      <td>TOC_DOC</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>11</td>\n",
       "      <td>1.561364</td>\n",
       "      <td>1.385000</td>\n",
       "      <td>0.554342</td>\n",
       "      <td>4</td>\n",
       "      <td>0.312348</td>\n",
       "      <td>0.754776</td>\n",
       "      <td>0.009286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    station_id         parameter     period  nonmiss     average      median  \\\n",
       "0        23499                AL  1990-2004       15  486.052433  503.500000   \n",
       "1        23499               ALK  1990-2004       14  -15.896429  -15.850000   \n",
       "2        23499               ANC  1990-2004       12  -47.948231  -53.510865   \n",
       "3        23499            ECAEMG  1990-2004       15   84.136540   83.398845   \n",
       "4        23499          ECAXEMGX  1990-2004       15   79.221717   78.338350   \n",
       "5        23499               ECL  1990-2004       15   21.093655   21.718895   \n",
       "6        23499              ENO3  1990-2004       12   65.111360   66.036608   \n",
       "7        23499  ENO3DIVENO3ESO4X  1990-2004       12    0.428599    0.427500   \n",
       "8        23499              ESO4  1990-2004       15   95.643491   97.541580   \n",
       "9        23499            ESO4CL  1990-2004       15  116.737145  118.934785   \n",
       "10       23499       ESO4ECLENO3  1990-2004       12  175.508512  176.306256   \n",
       "11       23499             ESO4X  1990-2004       15   93.470844   95.253690   \n",
       "12       23499            HPLUSS  1990-2004       15   18.383278   18.506625   \n",
       "13       23499           TOC_DOC  1990-2004       11    1.561364    1.385000   \n",
       "\n",
       "         stdev  test_stat   mk_stat       mkp   senslope  \n",
       "0   186.876929        -83 -4.107435  0.000040 -32.700000  \n",
       "1     6.270918         20  1.096542  0.272842   0.500000  \n",
       "2    14.813228         48  3.291482  0.000997   3.178531  \n",
       "3     9.581870        -75 -3.711537  0.000206  -1.968997  \n",
       "4     9.248877        -71 -3.513589  0.000442  -1.886138  \n",
       "5     2.980660        -44 -2.180106  0.029250  -0.435917  \n",
       "6     7.299949        -40 -2.742902  0.006090  -1.234397  \n",
       "7     0.028221         32  2.194322  0.028212   0.006281  \n",
       "8    18.305102        -97 -4.800255  0.000002  -4.089638  \n",
       "9    20.274570        -95 -4.701281  0.000003  -4.449103  \n",
       "10   23.280313        -52 -3.565772  0.000363  -5.589727  \n",
       "11   18.117947        -97 -4.800255  0.000002  -4.033607  \n",
       "12    4.313829        -69 -3.414614  0.000639  -0.795074  \n",
       "13    0.554342          4  0.312348  0.754776   0.009286  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get results for test sites from RESA2\n",
    "sql = (\"SELECT * FROM resa2.icpw_statistics3 \"\n",
    "       \"WHERE station_id = 23499 \"\n",
    "       \"AND period = '1990-2004'\")\n",
    "\n",
    "old_df = pd.read_sql(sql, engine)\n",
    "\n",
    "# Get just the cols to compare to my output\n",
    "old_df = old_df[['station_id', 'parameter', 'period', 'nonmiss',\n",
    "                   'average', 'median', 'stdev', 'test_stat', \n",
    "                   'mk_stat', 'mkp', 'senslope']]\n",
    "\n",
    "old_df.head(14).sort_values(by='parameter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Run new code\n",
    "\n",
    "The above table shows output from the previous analysis for the period from 1990 to 2004. The code below runs my new trend analysis for all of the Czech sites (`project_name = 'ICPW_TOCTRENDS_2015_CZ'`) for the same period and then prints just the results for site 23499 for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from RESA2...\n",
      "    Done.\n",
      "\n",
      "Converting units and applying sea-salt correction...\n",
      "    Done.\n",
      "\n",
      "Calculating statistics...\n",
      "    Done.\n",
      "\n",
      "Finished.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>par_id</th>\n",
       "      <th>period</th>\n",
       "      <th>non_missing</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>mk_stat</th>\n",
       "      <th>norm_mk_stat</th>\n",
       "      <th>mk_p_val</th>\n",
       "      <th>trend</th>\n",
       "      <th>sen_slp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23499</td>\n",
       "      <td>Al</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>485.085767</td>\n",
       "      <td>503.500000</td>\n",
       "      <td>187.586374</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>-4.057948</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-33.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23499</td>\n",
       "      <td>ECa</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>44.283333</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>5.584470</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-3.662050</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-1.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23499</td>\n",
       "      <td>ECaX</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>43.489771</td>\n",
       "      <td>43.186000</td>\n",
       "      <td>5.524900</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-3.662050</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-1.179175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>23499</td>\n",
       "      <td>ECaX_EMgX</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>79.786038</td>\n",
       "      <td>78.874000</td>\n",
       "      <td>9.366281</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-3.464102</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-1.899667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23499</td>\n",
       "      <td>ECa_EMg</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>84.783333</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>9.708540</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>-3.563076</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-1.981481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23499</td>\n",
       "      <td>ECl</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>21.447619</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.017861</td>\n",
       "      <td>-44.0</td>\n",
       "      <td>-2.130559</td>\n",
       "      <td>0.033126</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-0.441558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23499</td>\n",
       "      <td>EMg</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>4.170237</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-3.671052</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23499</td>\n",
       "      <td>EMgX</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>36.296267</td>\n",
       "      <td>35.930000</td>\n",
       "      <td>3.924888</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>-3.266153</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-0.739152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23499</td>\n",
       "      <td>ENO3</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>12</td>\n",
       "      <td>64.866071</td>\n",
       "      <td>66.037500</td>\n",
       "      <td>7.380028</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>-2.674329</td>\n",
       "      <td>0.007488</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-1.278393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23499</td>\n",
       "      <td>ESO4</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>95.625000</td>\n",
       "      <td>98.125000</td>\n",
       "      <td>18.527533</td>\n",
       "      <td>-95.0</td>\n",
       "      <td>-4.651794</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-4.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23499</td>\n",
       "      <td>ESO4X</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>93.415895</td>\n",
       "      <td>95.947286</td>\n",
       "      <td>18.336954</td>\n",
       "      <td>-95.0</td>\n",
       "      <td>-4.651794</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-3.965619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23499</td>\n",
       "      <td>ESO4_ECl</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>15</td>\n",
       "      <td>117.072619</td>\n",
       "      <td>119.267857</td>\n",
       "      <td>20.531061</td>\n",
       "      <td>-95.0</td>\n",
       "      <td>-4.651794</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-4.457792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>23499</td>\n",
       "      <td>ESO4_ECl_ENO3</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>12</td>\n",
       "      <td>175.649554</td>\n",
       "      <td>176.662202</td>\n",
       "      <td>23.824901</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>-3.360055</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-5.648674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23499</td>\n",
       "      <td>TOC</td>\n",
       "      <td>1990-2004</td>\n",
       "      <td>11</td>\n",
       "      <td>1.561364</td>\n",
       "      <td>1.385000</td>\n",
       "      <td>0.554342</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.234261</td>\n",
       "      <td>0.814783</td>\n",
       "      <td>no trend</td>\n",
       "      <td>0.009286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    station_id         par_id     period  non_missing        mean      median  \\\n",
       "0        23499             Al  1990-2004           15  485.085767  503.500000   \n",
       "5        23499            ECa  1990-2004           15   44.283333   44.000000   \n",
       "9        23499           ECaX  1990-2004           15   43.489771   43.186000   \n",
       "12       23499      ECaX_EMgX  1990-2004           15   79.786038   78.874000   \n",
       "11       23499        ECa_EMg  1990-2004           15   84.783333   84.000000   \n",
       "3        23499            ECl  1990-2004           15   21.447619   22.000000   \n",
       "4        23499            EMg  1990-2004           15   40.500000   40.000000   \n",
       "8        23499           EMgX  1990-2004           15   36.296267   35.930000   \n",
       "6        23499           ENO3  1990-2004           12   64.866071   66.037500   \n",
       "2        23499           ESO4  1990-2004           15   95.625000   98.125000   \n",
       "7        23499          ESO4X  1990-2004           15   93.415895   95.947286   \n",
       "10       23499       ESO4_ECl  1990-2004           15  117.072619  119.267857   \n",
       "13       23499  ESO4_ECl_ENO3  1990-2004           12  175.649554  176.662202   \n",
       "1        23499            TOC  1990-2004           11    1.561364    1.385000   \n",
       "\n",
       "       std_dev  mk_stat  norm_mk_stat  mk_p_val       trend    sen_slp  \n",
       "0   187.586374    -83.0     -4.057948  0.000050  decreasing -33.200000  \n",
       "5     5.584470    -75.0     -3.662050  0.000250  decreasing  -1.166667  \n",
       "9     5.524900    -75.0     -3.662050  0.000250  decreasing  -1.179175  \n",
       "12    9.366281    -71.0     -3.464102  0.000532  decreasing  -1.899667  \n",
       "11    9.708540    -73.0     -3.563076  0.000367  decreasing  -1.981481  \n",
       "3     3.017861    -44.0     -2.130559  0.033126  decreasing  -0.441558  \n",
       "4     4.170237    -75.0     -3.671052  0.000242  decreasing  -0.833333  \n",
       "8     3.924888    -67.0     -3.266153  0.001090  decreasing  -0.739152  \n",
       "6     7.380028    -40.0     -2.674329  0.007488  decreasing  -1.278393  \n",
       "2    18.527533    -95.0     -4.651794  0.000003  decreasing  -4.083333  \n",
       "7    18.336954    -95.0     -4.651794  0.000003  decreasing  -3.965619  \n",
       "10   20.531061    -95.0     -4.651794  0.000003  decreasing  -4.457792  \n",
       "13   23.824901    -50.0     -3.360055  0.000779  decreasing  -5.648674  \n",
       "1     0.554342      4.0      0.234261  0.814783    no trend   0.009286  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify projects of interest\n",
    "proj_list = ['ICPW_TOCTRENDS_2015_CZ',]\n",
    "\n",
    "# Run analysis for the period 1990 - 2004\n",
    "new_df, dup_df, no_data_df = resa2_trends.run_trend_analysis(proj_list, engine,\n",
    "                                                             st_yr=1990, end_yr=2004)\n",
    "\n",
    "# Delete mk_std_dev col as not relevant here\n",
    "del new_df['mk_std_dev']\n",
    "\n",
    "new_df.head(14).sort_values(by='par_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results from my code are not *exactly* the same as the output produced by Tore, but **for all practical purposes I'd say the differences are negligible**. This is actually pretty surprising given the amount of second-guessing and reverse-engineering that went into developing my code. \n",
    "\n",
    "## 3. Analysis of the full TOC trends dataset\n",
    "\n",
    "The next big question is whether my code will upscale effectively to the full TOC dataset. The RESA2 application usually crashes if a user tries to extract data for more than one large project at a time, but I'm hoping that by bypassing RESA2 and communicating directly with the underlying Oracle instance, my code will not be affected by this issue.\n",
    "\n",
    "This section attempts to run the trends analysis on the full TOC dataset. Initially I'll use the data for **all years** and I'll also **generate plots for each series** (which I'll return to later). The projects to be included have been previously agreed with Heleen - see [section 3 of this notebook](http://nbviewer.jupyter.org/url/www.googledrive.com/host/0BximeC_RweaeUy1jd2k3Nm1kdms/toc_trends_2015_data_cleaning.ipynb#3.-Site-properties-(location,-land-use-and-elevation) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from RESA2...\n",
      "    The database contains duplicate values for some station-date-parameter combinations.\n",
      "    These will be averaged, but you should check the repeated values are not errors.\n",
      "    The duplicated entries are returned in a separate dataframe.\n",
      "\n",
      "    Some stations have no relevant data in the period specified. Their IDs are returned in a separate dataframe.\n",
      "\n",
      "    Done.\n",
      "\n",
      "Converting units and applying sea-salt correction...\n",
      "    Done.\n",
      "\n",
      "Calculating statistics...\n",
      "    Data series for Al at site 101 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 102 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 103 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 104 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 107 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 109 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 112 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 115 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 118 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 119 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 120 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 121 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 122 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 123 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 128 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 132 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 134 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 135 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 144 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 146 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 147 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 150 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 156 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 158 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 161 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 162 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 163 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 166 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 168 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 170 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 173 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 176 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 179 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 180 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 181 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 182 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 183 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 185 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 192 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 193 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 196 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 12081 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 23546 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 36547 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Data series for Al at site 36560 has fewer than 10 non-null values. Significance estimates may be unreliable.\n",
      "    Done.\n",
      "\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "# Specify projects of interest\n",
    "proj_list = ['ICPW_TOCTRENDS_2015_CA_ATL',\n",
    "             'ICPW_TOCTRENDS_2015_CA_DO',\n",
    "             'ICPW_TOCTRENDS_2015_CA_ICPW',\n",
    "             'ICPW_TOCTRENDS_2015_CA_NF',\n",
    "             'ICPW_TOCTRENDS_2015_CA_QU',\n",
    "             'ICPW_TOCTRENDS_2015_CZ',\n",
    "             'ICPW_TOCTRENDS_2015_Cz2',\n",
    "             'ICPW_TOCTRENDS_2015_FI',\n",
    "             'ICPW_TOCTRENDS_2015_NO',\n",
    "             'ICPW_TOCTRENDS_2015_SE',\n",
    "             'ICPW_TOCTRENDS_2015_UK',\n",
    "             'ICPW_TOCTRENDS_2015_US_LTM',\n",
    "             'ICPWaters Ca']\n",
    "\n",
    "# Folder for saving PNG plots\n",
    "plot_fold=r'C:\\Data\\James_Work\\Staff\\Heleen_d_W\\ICP_Waters\\TOC_Trends_Analysis_2015\\Trends_Plots'\n",
    "\n",
    "# Run analysis\n",
    "res_df, dup_df, no_data_df = resa2_trends.run_trend_analysis(proj_list, engine,\n",
    "                                                             st_yr=None, end_yr=None,\n",
    "                                                             plot=True, fold=plot_fold)\n",
    "\n",
    "# Delete mk_std_dev col as not relevant here\n",
    "del res_df['mk_std_dev']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Results\n",
    "\n",
    "It's good to see the algorithm manages to process all the sites in one go. The table below shows the first 10 rows of the output, but it's the warning messages that I'm most interested in at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>par_id</th>\n",
       "      <th>period</th>\n",
       "      <th>non_missing</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>mk_stat</th>\n",
       "      <th>norm_mk_stat</th>\n",
       "      <th>mk_p_val</th>\n",
       "      <th>trend</th>\n",
       "      <th>sen_slp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>Al</td>\n",
       "      <td>1986-2015</td>\n",
       "      <td>1</td>\n",
       "      <td>276.433655</td>\n",
       "      <td>276.433655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>TOC</td>\n",
       "      <td>1986-2015</td>\n",
       "      <td>28</td>\n",
       "      <td>6.053929</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.277101</td>\n",
       "      <td>221.0</td>\n",
       "      <td>4.351249</td>\n",
       "      <td>1.353642e-05</td>\n",
       "      <td>increasing</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>ESO4</td>\n",
       "      <td>1986-2015</td>\n",
       "      <td>28</td>\n",
       "      <td>37.526786</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>18.794670</td>\n",
       "      <td>-327.0</td>\n",
       "      <td>-6.446919</td>\n",
       "      <td>1.141465e-10</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-2.001984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>ECl</td>\n",
       "      <td>1986-2015</td>\n",
       "      <td>28</td>\n",
       "      <td>18.061224</td>\n",
       "      <td>17.142857</td>\n",
       "      <td>3.572260</td>\n",
       "      <td>-120.0</td>\n",
       "      <td>-2.369597</td>\n",
       "      <td>1.780750e-02</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-0.184694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0</td>\n",
       "      <td>EMg</td>\n",
       "      <td>1986-2015</td>\n",
       "      <td>28</td>\n",
       "      <td>10.711310</td>\n",
       "      <td>10.833333</td>\n",
       "      <td>2.028790</td>\n",
       "      <td>-134.0</td>\n",
       "      <td>-2.652231</td>\n",
       "      <td>7.996170e-03</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-0.133025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.0</td>\n",
       "      <td>ECa</td>\n",
       "      <td>1986-2015</td>\n",
       "      <td>28</td>\n",
       "      <td>18.607143</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>3.090029</td>\n",
       "      <td>-126.0</td>\n",
       "      <td>-2.474722</td>\n",
       "      <td>1.333399e-02</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100.0</td>\n",
       "      <td>ENO3</td>\n",
       "      <td>1986-2015</td>\n",
       "      <td>28</td>\n",
       "      <td>2.418367</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.526747</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.791033</td>\n",
       "      <td>4.289247e-01</td>\n",
       "      <td>no trend</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100.0</td>\n",
       "      <td>ESO4X</td>\n",
       "      <td>1986-2015</td>\n",
       "      <td>28</td>\n",
       "      <td>35.666480</td>\n",
       "      <td>29.778571</td>\n",
       "      <td>18.611860</td>\n",
       "      <td>-329.0</td>\n",
       "      <td>-6.481403</td>\n",
       "      <td>9.087331e-11</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-1.945556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100.0</td>\n",
       "      <td>EMgX</td>\n",
       "      <td>1986-2015</td>\n",
       "      <td>28</td>\n",
       "      <td>7.171310</td>\n",
       "      <td>6.860667</td>\n",
       "      <td>1.698371</td>\n",
       "      <td>-123.0</td>\n",
       "      <td>-2.410766</td>\n",
       "      <td>1.591906e-02</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-0.102902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100.0</td>\n",
       "      <td>ECaX</td>\n",
       "      <td>1986-2015</td>\n",
       "      <td>28</td>\n",
       "      <td>17.938878</td>\n",
       "      <td>18.068143</td>\n",
       "      <td>3.040012</td>\n",
       "      <td>-122.0</td>\n",
       "      <td>-2.390539</td>\n",
       "      <td>1.682367e-02</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-0.182602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id par_id     period  non_missing        mean      median  \\\n",
       "0       100.0     Al  1986-2015            1  276.433655  276.433655   \n",
       "1       100.0    TOC  1986-2015           28    6.053929    6.000000   \n",
       "2       100.0   ESO4  1986-2015           28   37.526786   31.250000   \n",
       "3       100.0    ECl  1986-2015           28   18.061224   17.142857   \n",
       "4       100.0    EMg  1986-2015           28   10.711310   10.833333   \n",
       "5       100.0    ECa  1986-2015           28   18.607143   18.750000   \n",
       "6       100.0   ENO3  1986-2015           28    2.418367    2.000000   \n",
       "7       100.0  ESO4X  1986-2015           28   35.666480   29.778571   \n",
       "8       100.0   EMgX  1986-2015           28    7.171310    6.860667   \n",
       "9       100.0   ECaX  1986-2015           28   17.938878   18.068143   \n",
       "\n",
       "     std_dev  mk_stat  norm_mk_stat      mk_p_val       trend   sen_slp  \n",
       "0        NaN      NaN           NaN           NaN         NaN       NaN  \n",
       "1   1.277101    221.0      4.351249  1.353642e-05  increasing  0.100000  \n",
       "2  18.794670   -327.0     -6.446919  1.141465e-10  decreasing -2.001984  \n",
       "3   3.572260   -120.0     -2.369597  1.780750e-02  decreasing -0.184694  \n",
       "4   2.028790   -134.0     -2.652231  7.996170e-03  decreasing -0.133025  \n",
       "5   3.090029   -126.0     -2.474722  1.333399e-02  decreasing -0.187500  \n",
       "6   1.526747     41.0      0.791033  4.289247e-01    no trend  0.028571  \n",
       "7  18.611860   -329.0     -6.481403  9.087331e-11  decreasing -1.945556  \n",
       "8   1.698371   -123.0     -2.410766  1.591906e-02  decreasing -0.102902  \n",
       "9   3.040012   -122.0     -2.390539  1.682367e-02  decreasing -0.182602  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Data issues\n",
    "\n",
    "#### 3.2.1. Limited Al data\n",
    "\n",
    "Many of the sites have limited Al data. This isn't a database error, but it could have implications for our ability to detect trends for this parameter.\n",
    "\n",
    "#### 3.2.2. Sites with no data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sites with no data: 178\n",
      "Sites with no data come from the following countries:\n",
      "['Sweden']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_code</th>\n",
       "      <th>station_name</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36573</td>\n",
       "      <td>656612-164132</td>\n",
       "      <td>rsjn</td>\n",
       "      <td>Sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36574</td>\n",
       "      <td>655275-153234</td>\n",
       "      <td>lgsjn</td>\n",
       "      <td>Sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36577</td>\n",
       "      <td>656984-164254</td>\n",
       "      <td>Albysjn</td>\n",
       "      <td>Sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36579</td>\n",
       "      <td>665768-164748</td>\n",
       "      <td>Aspdalssjn</td>\n",
       "      <td>Sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36580</td>\n",
       "      <td>656832-161545</td>\n",
       "      <td>Aspen</td>\n",
       "      <td>Sweden</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id   station_code station_name country\n",
       "0       36573  656612-164132       rsjn  Sweden\n",
       "1       36574  655275-153234      lgsjn  Sweden\n",
       "2       36577  656984-164254     Albysjn  Sweden\n",
       "3       36579  665768-164748  Aspdalssjn  Sweden\n",
       "4       36580  656832-161545        Aspen  Sweden"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get properties for sites with no data\n",
    "# Basic station properties\n",
    "sql = ('SELECT station_id, station_code, station_name '\n",
    "       'FROM resa2.stations '\n",
    "       'WHERE station_id in %s' \n",
    "       % str(tuple(no_data_df['station_id'].values)))\n",
    "\n",
    "na_stns = pd.read_sql(sql, engine)\n",
    "\n",
    "# Get country for each station\n",
    "sql = ('SELECT station_id, value '\n",
    "       'FROM resa2.stations_par_values '\n",
    "       'WHERE station_id in %s '\n",
    "       'AND var_id = 261'\n",
    "       % str(tuple(no_data_df['station_id'].values)))\n",
    "\n",
    "co_df = pd.read_sql(sql, engine)\n",
    "\n",
    "# Decode special characters fro `windows-1252` encoding to unicode\n",
    "na_stns['station_name'] = na_stns['station_name'].str.decode('windows-1252')\n",
    "\n",
    "# Join\n",
    "na_stns = pd.merge(na_stns, co_df, how='left',\n",
    "                   on='station_id')\n",
    "\n",
    "na_stns.columns = ['station_id', 'station_code', 'station_name', 'country']\n",
    "\n",
    "print 'Number of sites with no data:', len(no_data_df)\n",
    "print 'Sites with no data come from the following countries:'\n",
    "print list(na_stns.country.unique())\n",
    "\n",
    "na_stns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 178 Swedish sites (out of 261 in total) that have no data whatsoever for the parameters $SO_4$, $Cl$, $Ca$, $Mg$, $NO_3$, $TOC$ or $Al$. It seems strange to have these included in a project focussing on TOC trends! Perhaps they're included due to having data for other useful parameters? Let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples associated with the 178 Swedish sites (for ALL parameters): 0\n"
     ]
    }
   ],
   "source": [
    "# Find ANY parameters associated with the 178 Swedish sites\n",
    "sql = ('SELECT * '\n",
    "       'FROM resa2.water_samples '\n",
    "       'WHERE station_id in %s' \n",
    "       % str(tuple(no_data_df['station_id'].values)))\n",
    "\n",
    "swed_df = pd.read_sql(sql, engine)\n",
    "\n",
    "print 'Number of samples associated with the 178 Swedish sites (for ALL parameters):', len(swed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it appears that more than two-thirds of the Swedish sites in the database have *no data at all*. **Is this expected, or has something gone wrong here?**\n",
    "\n",
    "#### 3.2.3. Duplicated values\n",
    "\n",
    "Some duplicate values are expected, because at some sites samples are taken at a variety of depths. My algorithm currently only selects samples from the upper 1 m of the water column, but this occasionally spans two depth measuremnts (usually 0 and 0.5 m). For the moment, it seems reasonable to **average** these values (and in most cases they are near-identical anyway), but **check this with Heleen and modify the code if necessary**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of duplicated records: 2617\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>sample_date</th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>103.0</td>\n",
       "      <td>1974-10-29</td>\n",
       "      <td>Ca</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57232</th>\n",
       "      <td>103.0</td>\n",
       "      <td>1974-10-29</td>\n",
       "      <td>Ca</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>103.0</td>\n",
       "      <td>1974-10-29</td>\n",
       "      <td>Cl</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57233</th>\n",
       "      <td>103.0</td>\n",
       "      <td>1974-10-29</td>\n",
       "      <td>Cl</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>103.0</td>\n",
       "      <td>1974-10-29</td>\n",
       "      <td>Mg</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57234</th>\n",
       "      <td>103.0</td>\n",
       "      <td>1974-10-29</td>\n",
       "      <td>Mg</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>103.0</td>\n",
       "      <td>1974-10-29</td>\n",
       "      <td>NO3-N</td>\n",
       "      <td>90.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57235</th>\n",
       "      <td>103.0</td>\n",
       "      <td>1974-10-29</td>\n",
       "      <td>NO3-N</td>\n",
       "      <td>90.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>104.0</td>\n",
       "      <td>1974-11-05</td>\n",
       "      <td>Ca</td>\n",
       "      <td>2.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57242</th>\n",
       "      <td>104.0</td>\n",
       "      <td>1974-11-05</td>\n",
       "      <td>Ca</td>\n",
       "      <td>2.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       station_id sample_date   name  value\n",
       "1270        103.0  1974-10-29     Ca   1.25\n",
       "57232       103.0  1974-10-29     Ca   1.25\n",
       "1271        103.0  1974-10-29     Cl   4.40\n",
       "57233       103.0  1974-10-29     Cl   4.40\n",
       "1272        103.0  1974-10-29     Mg   0.74\n",
       "57234       103.0  1974-10-29     Mg   0.74\n",
       "1273        103.0  1974-10-29  NO3-N  90.00\n",
       "57235       103.0  1974-10-29  NO3-N  90.00\n",
       "6           104.0  1974-11-05     Ca   2.07\n",
       "57242       104.0  1974-11-05     Ca   2.07"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'Total number of duplicated records:', len(dup_df)\n",
    "\n",
    "dup_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Not all the duplicates can be explained by measuring at multiple depths, though, and occasionally the repeated values are significantly different. As an example, consider records for site 28970 (which corresponds to site code `NF02YH0013`, in Newfoundland, Canada)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>sample_date</th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125050</th>\n",
       "      <td>28970.0</td>\n",
       "      <td>1990-06-29</td>\n",
       "      <td>NO3-N</td>\n",
       "      <td>25.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125053</th>\n",
       "      <td>28970.0</td>\n",
       "      <td>1990-06-29</td>\n",
       "      <td>NO3-N</td>\n",
       "      <td>110.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125052</th>\n",
       "      <td>28970.0</td>\n",
       "      <td>1990-06-29</td>\n",
       "      <td>TOC</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125054</th>\n",
       "      <td>28970.0</td>\n",
       "      <td>1990-06-29</td>\n",
       "      <td>TOC</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125059</th>\n",
       "      <td>28970.0</td>\n",
       "      <td>1990-10-18</td>\n",
       "      <td>NO3-N</td>\n",
       "      <td>23.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125062</th>\n",
       "      <td>28970.0</td>\n",
       "      <td>1990-10-18</td>\n",
       "      <td>NO3-N</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125061</th>\n",
       "      <td>28970.0</td>\n",
       "      <td>1990-10-18</td>\n",
       "      <td>TOC</td>\n",
       "      <td>0.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125063</th>\n",
       "      <td>28970.0</td>\n",
       "      <td>1990-10-18</td>\n",
       "      <td>TOC</td>\n",
       "      <td>0.8960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125068</th>\n",
       "      <td>28970.0</td>\n",
       "      <td>1991-06-19</td>\n",
       "      <td>NO3-N</td>\n",
       "      <td>25.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379302</th>\n",
       "      <td>28970.0</td>\n",
       "      <td>1991-06-19</td>\n",
       "      <td>NO3-N</td>\n",
       "      <td>110.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        station_id sample_date   name     value\n",
       "125050     28970.0  1990-06-29  NO3-N   25.0000\n",
       "125053     28970.0  1990-06-29  NO3-N  110.0000\n",
       "125052     28970.0  1990-06-29    TOC    0.3125\n",
       "125054     28970.0  1990-06-29    TOC    0.6400\n",
       "125059     28970.0  1990-10-18  NO3-N   23.0000\n",
       "125062     28970.0  1990-10-18  NO3-N  100.0000\n",
       "125061     28970.0  1990-10-18    TOC    0.8750\n",
       "125063     28970.0  1990-10-18    TOC    0.8960\n",
       "125068     28970.0  1991-06-19  NO3-N   25.0000\n",
       "379302     28970.0  1991-06-19  NO3-N  110.0000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the duplicated values for this site\n",
    "dup_df.query('station_id == 28970').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are lots of duplciated records here, and the values are not the same. Let's have a look at the database results for the first water sample in this series (the one from 29/06/1990), where we apparently have repeated measurements for `NO3-N` and `TOC`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>method_id</th>\n",
       "      <th>value</th>\n",
       "      <th>flag1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7440578</td>\n",
       "      <td>328339</td>\n",
       "      <td>10249</td>\n",
       "      <td>79.0000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3621153</td>\n",
       "      <td>328339</td>\n",
       "      <td>10251</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3621154</td>\n",
       "      <td>328339</td>\n",
       "      <td>10253</td>\n",
       "      <td>2.5000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7440581</td>\n",
       "      <td>328339</td>\n",
       "      <td>10256</td>\n",
       "      <td>15.0000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3621155</td>\n",
       "      <td>328339</td>\n",
       "      <td>10258</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7440583</td>\n",
       "      <td>328339</td>\n",
       "      <td>10260</td>\n",
       "      <td>17.1000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3621156</td>\n",
       "      <td>328339</td>\n",
       "      <td>10261</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3621157</td>\n",
       "      <td>328339</td>\n",
       "      <td>10263</td>\n",
       "      <td>1.5000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7440586</td>\n",
       "      <td>328339</td>\n",
       "      <td>10265</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3621158</td>\n",
       "      <td>328339</td>\n",
       "      <td>10268</td>\n",
       "      <td>5.1000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3621159</td>\n",
       "      <td>328339</td>\n",
       "      <td>10271</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3621160</td>\n",
       "      <td>328339</td>\n",
       "      <td>10273</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7440589</td>\n",
       "      <td>328339</td>\n",
       "      <td>10274</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7440591</td>\n",
       "      <td>328339</td>\n",
       "      <td>10298</td>\n",
       "      <td>-6.0000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3621161</td>\n",
       "      <td>328339</td>\n",
       "      <td>10308</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3621162</td>\n",
       "      <td>328339</td>\n",
       "      <td>10311</td>\n",
       "      <td>-0.3000</td>\n",
       "      <td>&lt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7440590</td>\n",
       "      <td>328339</td>\n",
       "      <td>10823</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    value_id  sample_id  method_id     value flag1\n",
       "0    7440578     328339      10249   79.0000  None\n",
       "1    3621153     328339      10251    0.2200  None\n",
       "2    3621154     328339      10253    2.5000  None\n",
       "3    7440581     328339      10256   15.0000  None\n",
       "4    3621155     328339      10258    0.1400  None\n",
       "5    7440583     328339      10260   17.1000  None\n",
       "6    3621156     328339      10261    0.2200  None\n",
       "7    3621157     328339      10263    1.5000  None\n",
       "8    7440586     328339      10265   25.0000  None\n",
       "9    3621158     328339      10268    5.1000  None\n",
       "10   3621159     328339      10271    1.0000  None\n",
       "11   3621160     328339      10273    0.3125  None\n",
       "12   7440589     328339      10274  100.0000  None\n",
       "13   7440591     328339      10298   -6.0000  None\n",
       "14   3621161     328339      10308    0.1100  None\n",
       "15   3621162     328339      10311   -0.3000     <\n",
       "16   7440590     328339      10823    0.5000  None"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all methods applied to sample(s) from 29/06/1990 at station 28970\n",
    "sql = (\"SELECT value_id, sample_id, method_id, value, flag1 \"\n",
    "       \"FROM resa2.water_chemistry_values2 \"\n",
    "       \"WHERE sample_id IN (SELECT water_sample_id FROM resa2.water_samples \"\n",
    "                           \"WHERE station_id = 28970 \"\n",
    "                           \"AND sample_date = DATE '1990-06-29')\")\n",
    "\n",
    "df = pd.read_sql(sql, engine)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that all these records have the same `sample_id`, which means the problem is not related to samples being entered into the database more than once. Instead, the problem seems to be due to entering multiple methods for the same parameter: `method_id = 10265` corresponds to NO3-N concentrations measured in $\\mu g/l$, whereas `method_id = 10308` refers to NO3-N in $mg/l$. As the data is extracted for the trends analysis, my code automatically converts all NO3-N measurements into $\\mu g/l$, which is why we end up with duplicate values of 25 and 110 in the trends results (see above). The puzzle is **where do these values come from in the first place**? $110 \\; \\mu g/l$ is, after all, a lot more than $25 \\; \\mu g/l$.\n",
    "\n",
    "Looking at the database log, the value of $0.110 \\; mg/l$ was uploaded on 16/02/2006, whereas the value of $25 \\; \\mu g/l$ was added on 16/11/2015. The only raw data I can find on the network for this location is here:\n",
    "\n",
    "K:\\Prosjekter\\langtransporterte forurensninger\\O-23300 - ICP-WATERS - HWI\\Database\\2015 DOC analysis\\data delivery\\CA\\Couture\\ICP Waters form for water chemistry_ATL_NF.xlsx\n",
    "\n",
    "which gives the nitrate concentraion as $25 \\; \\mu g/l$ (i.e. consistent with the most recent database upload). At present, I can't identify where the older values have come from, and I'm reluctant to delete them without further clarification. **Ask Heleen about this**, but for now I'll just stick with averaging duplicated values because I have no obvious way of choosing which one(s) are correct.\n",
    "\n",
    "## 4. Data visualisation\n",
    "\n",
    "I'd like to try producing a Google map to visualise the results of the statistical analysis. If I automate this as much as possible, it should be easy to re-run the code once I'm happy with the basic input data.\n",
    "\n",
    "I'll start off by limiting the dataset so that we're only visualising the following parameters (and only in cases where there are more than 10 data values in the series):\n",
    "\n",
    "* ESO4 (eq/l)\n",
    "* ESO4X (eq/l)\n",
    "* ESO4X (eq/l)\n",
    "* ECl (eq/l)\n",
    "* ESO4_ECl (eq/l)\n",
    "* ECa_EMg (eq/l)\n",
    "* ECaX_EMgX (eq/l)\n",
    "* ENO3 (eq/l)\n",
    "* ESO4_ECl_ENO3 (eq/l)\n",
    "* TOC (mgC/l)\n",
    "* Al (mg/l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of stations to visualise: 428\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>par_id</th>\n",
       "      <th>period</th>\n",
       "      <th>non_missing</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>mk_stat</th>\n",
       "      <th>norm_mk_stat</th>\n",
       "      <th>mk_p_val</th>\n",
       "      <th>trend</th>\n",
       "      <th>sen_slp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>TOC</td>\n",
       "      <td>1986-2015</td>\n",
       "      <td>28</td>\n",
       "      <td>6.053929</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.277101</td>\n",
       "      <td>221.0</td>\n",
       "      <td>4.351249</td>\n",
       "      <td>1.353642e-05</td>\n",
       "      <td>increasing</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>ESO4</td>\n",
       "      <td>1986-2015</td>\n",
       "      <td>28</td>\n",
       "      <td>37.526786</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>18.794670</td>\n",
       "      <td>-327.0</td>\n",
       "      <td>-6.446919</td>\n",
       "      <td>1.141465e-10</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-2.001984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>ECl</td>\n",
       "      <td>1986-2015</td>\n",
       "      <td>28</td>\n",
       "      <td>18.061224</td>\n",
       "      <td>17.142857</td>\n",
       "      <td>3.572260</td>\n",
       "      <td>-120.0</td>\n",
       "      <td>-2.369597</td>\n",
       "      <td>1.780750e-02</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-0.184694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100.0</td>\n",
       "      <td>ENO3</td>\n",
       "      <td>1986-2015</td>\n",
       "      <td>28</td>\n",
       "      <td>2.418367</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.526747</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.791033</td>\n",
       "      <td>4.289247e-01</td>\n",
       "      <td>no trend</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100.0</td>\n",
       "      <td>ESO4X</td>\n",
       "      <td>1986-2015</td>\n",
       "      <td>28</td>\n",
       "      <td>35.666480</td>\n",
       "      <td>29.778571</td>\n",
       "      <td>18.611860</td>\n",
       "      <td>-329.0</td>\n",
       "      <td>-6.481403</td>\n",
       "      <td>9.087331e-11</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-1.945556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id par_id     period  non_missing       mean     median    std_dev  \\\n",
       "1       100.0    TOC  1986-2015           28   6.053929   6.000000   1.277101   \n",
       "2       100.0   ESO4  1986-2015           28  37.526786  31.250000  18.794670   \n",
       "3       100.0    ECl  1986-2015           28  18.061224  17.142857   3.572260   \n",
       "6       100.0   ENO3  1986-2015           28   2.418367   2.000000   1.526747   \n",
       "7       100.0  ESO4X  1986-2015           28  35.666480  29.778571  18.611860   \n",
       "\n",
       "   mk_stat  norm_mk_stat      mk_p_val       trend   sen_slp  \n",
       "1    221.0      4.351249  1.353642e-05  increasing  0.100000  \n",
       "2   -327.0     -6.446919  1.141465e-10  decreasing -2.001984  \n",
       "3   -120.0     -2.369597  1.780750e-02  decreasing -0.184694  \n",
       "6     41.0      0.791033  4.289247e-01    no trend  0.028571  \n",
       "7   -329.0     -6.481403  9.087331e-11  decreasing -1.945556  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract subset of results to visualise\n",
    "par_str = str(('ESO4', 'ESO4X', 'ESO4X', \n",
    "               'ECl', 'ESO4_ECl', 'ECa_EMg', \n",
    "               'ECaX_EMgX', 'ENO3', 'ESO4_ECl_ENO3', \n",
    "               'TOC', 'Al'))\n",
    "\n",
    "vis_df = res_df.query(\"(par_id in %s) and (non_missing >= 10)\" % par_str)\n",
    "\n",
    "print 'Total number of stations to visualise:', len(vis_df['station_id'].unique())\n",
    "\n",
    "vis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_code</th>\n",
       "      <th>station_name</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>par_id</th>\n",
       "      <th>period</th>\n",
       "      <th>non_missing</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>mk_stat</th>\n",
       "      <th>norm_mk_stat</th>\n",
       "      <th>mk_p_val</th>\n",
       "      <th>trend</th>\n",
       "      <th>sen_slp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>623-603</td>\n",
       "      <td>Breidlivatnet</td>\n",
       "      <td>Norway</td>\n",
       "      <td>59.977669</td>\n",
       "      <td>10.152037</td>\n",
       "      <td>TOC</td>\n",
       "      <td>1986-2015</td>\n",
       "      <td>28</td>\n",
       "      <td>6.053929</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.277101</td>\n",
       "      <td>221.0</td>\n",
       "      <td>4.351249</td>\n",
       "      <td>1.353642e-05</td>\n",
       "      <td>increasing</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>623-603</td>\n",
       "      <td>Breidlivatnet</td>\n",
       "      <td>Norway</td>\n",
       "      <td>59.977669</td>\n",
       "      <td>10.152037</td>\n",
       "      <td>ESO4</td>\n",
       "      <td>1986-2015</td>\n",
       "      <td>28</td>\n",
       "      <td>37.526786</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>18.794670</td>\n",
       "      <td>-327.0</td>\n",
       "      <td>-6.446919</td>\n",
       "      <td>1.141465e-10</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-2.001984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>623-603</td>\n",
       "      <td>Breidlivatnet</td>\n",
       "      <td>Norway</td>\n",
       "      <td>59.977669</td>\n",
       "      <td>10.152037</td>\n",
       "      <td>ECl</td>\n",
       "      <td>1986-2015</td>\n",
       "      <td>28</td>\n",
       "      <td>18.061224</td>\n",
       "      <td>17.142857</td>\n",
       "      <td>3.572260</td>\n",
       "      <td>-120.0</td>\n",
       "      <td>-2.369597</td>\n",
       "      <td>1.780750e-02</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-0.184694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>623-603</td>\n",
       "      <td>Breidlivatnet</td>\n",
       "      <td>Norway</td>\n",
       "      <td>59.977669</td>\n",
       "      <td>10.152037</td>\n",
       "      <td>ENO3</td>\n",
       "      <td>1986-2015</td>\n",
       "      <td>28</td>\n",
       "      <td>2.418367</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.526747</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.791033</td>\n",
       "      <td>4.289247e-01</td>\n",
       "      <td>no trend</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0</td>\n",
       "      <td>623-603</td>\n",
       "      <td>Breidlivatnet</td>\n",
       "      <td>Norway</td>\n",
       "      <td>59.977669</td>\n",
       "      <td>10.152037</td>\n",
       "      <td>ESO4X</td>\n",
       "      <td>1986-2015</td>\n",
       "      <td>28</td>\n",
       "      <td>35.666480</td>\n",
       "      <td>29.778571</td>\n",
       "      <td>18.611860</td>\n",
       "      <td>-329.0</td>\n",
       "      <td>-6.481403</td>\n",
       "      <td>9.087331e-11</td>\n",
       "      <td>decreasing</td>\n",
       "      <td>-1.945556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id station_code   station_name country   latitude  longitude  \\\n",
       "0       100.0      623-603  Breidlivatnet  Norway  59.977669  10.152037   \n",
       "1       100.0      623-603  Breidlivatnet  Norway  59.977669  10.152037   \n",
       "2       100.0      623-603  Breidlivatnet  Norway  59.977669  10.152037   \n",
       "3       100.0      623-603  Breidlivatnet  Norway  59.977669  10.152037   \n",
       "4       100.0      623-603  Breidlivatnet  Norway  59.977669  10.152037   \n",
       "\n",
       "  par_id     period  non_missing       mean     median    std_dev  mk_stat  \\\n",
       "0    TOC  1986-2015           28   6.053929   6.000000   1.277101    221.0   \n",
       "1   ESO4  1986-2015           28  37.526786  31.250000  18.794670   -327.0   \n",
       "2    ECl  1986-2015           28  18.061224  17.142857   3.572260   -120.0   \n",
       "3   ENO3  1986-2015           28   2.418367   2.000000   1.526747     41.0   \n",
       "4  ESO4X  1986-2015           28  35.666480  29.778571  18.611860   -329.0   \n",
       "\n",
       "   norm_mk_stat      mk_p_val       trend   sen_slp  \n",
       "0      4.351249  1.353642e-05  increasing  0.100000  \n",
       "1     -6.446919  1.141465e-10  decreasing -2.001984  \n",
       "2     -2.369597  1.780750e-02  decreasing -0.184694  \n",
       "3      0.791033  4.289247e-01    no trend  0.028571  \n",
       "4     -6.481403  9.087331e-11  decreasing -1.945556  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join in station details\n",
    "\n",
    "# Basic station properties\n",
    "sql = ('SELECT station_id, station_code, station_name, latitude, longitude '\n",
    "       'FROM resa2.stations '\n",
    "       'WHERE station_id in %s' \n",
    "       % str(tuple(vis_df['station_id'].unique())))\n",
    "\n",
    "vis_stns = pd.read_sql(sql, engine)\n",
    "\n",
    "# Get country for each station\n",
    "sql = ('SELECT station_id, value '\n",
    "       'FROM resa2.stations_par_values '\n",
    "       'WHERE station_id in %s '\n",
    "       'AND var_id = 261'\n",
    "       % str(tuple(vis_df['station_id'].unique())))\n",
    "\n",
    "co_df = pd.read_sql(sql, engine)\n",
    "\n",
    "# Decode special characters fro `windows-1252` encoding to unicode\n",
    "vis_stns['station_name'] = vis_stns['station_name'].str.decode('windows-1252')\n",
    "\n",
    "# Join\n",
    "vis_stns = pd.merge(vis_stns, co_df, how='left',\n",
    "                    on='station_id')\n",
    "\n",
    "vis_stns.columns = ['station_id', 'station_code', 'station_name', \n",
    "                    'latitude', 'longitude', 'country']\n",
    "\n",
    "# Join to stats output\n",
    "vis_df = pd.merge(vis_df, vis_stns, how='left',\n",
    "                  on='station_id')\n",
    "\n",
    "# Reorder\n",
    "vis_df = vis_df[['station_id', 'station_code', 'station_name', 'country',\n",
    "                 'latitude', 'longitude', 'par_id', 'period', 'non_missing',\n",
    "                 'mean', 'median', 'std_dev', 'mk_stat', 'norm_mk_stat',\n",
    "                 'mk_p_val', 'trend', 'sen_slp']]\n",
    "\n",
    "vis_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In section 3, I generated a very large number of plots. Only some of them are relevant, so to save storage space online I'll delete the ones that aren't relevant to the data in `vis_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Delete unnecessary plots\n",
    "# Folder path\n",
    "png_fold = r'C:\\Data\\James_Work\\Staff\\Heleen_d_W\\ICP_Waters\\TOC_Trends_Analysis_2015\\Trends_Plots'\n",
    "\n",
    "# Paths to keep\n",
    "keep_list = []\n",
    "for rec in vis_df.itertuples():\n",
    "    stn_id = rec.station_id\n",
    "    par_id = rec.par_id\n",
    "    period = rec.period\n",
    "    \n",
    "    keep_path = os.path.join(png_fold,\n",
    "                             '%s_%s_%s.png' % (int(stn_id), par_id, period))\n",
    "    keep_list.append(keep_path)\n",
    "\n",
    "# Get a list of files in folder\n",
    "search_path = os.path.join(png_fold, '*.png')\n",
    "file_list = glob.glob(search_path)\n",
    "                             \n",
    "# Loop over files and delete where necessary\n",
    "del_list = []\n",
    "for file_path in file_list:\n",
    "    if file_path not in keep_list:\n",
    "        os.remove(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've uploaded the remaining plots to a location online, which means I can link to them from the map visualisation. To do this, I need to insert the link to each plot as a new column in `vis_df`. I also want to add a column to specify the correct [Google Fusion Tables marker symbol](https://www.google.com/fusiontables/DataSource?dsrcid=308519#map:id=3) according to the nature of the trend and, finally, I'd like to capitalise the `trend` column to improve the formating on my finsihed map. The whole thing then needs to be saved as a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Capitalise 'trend' column\n",
    "vis_df['trend'] = vis_df['trend'].str.capitalize()\n",
    "\n",
    "# Join in text for GFT markers\n",
    "mark_df = pd.DataFrame({'trend':['Increasing', 'No trend', 'Decreasing'],\n",
    "                        'symbol':['small_red', 'small_yellow', 'small_green']})\n",
    "\n",
    "vis_df = pd.merge(vis_df, mark_df, how='left',\n",
    "                  on='trend')\n",
    "\n",
    "# Build the link path\n",
    "link_stem = r'http://www.googledrive.com/host/0BximeC_RweaebnFoa2VWcGtRWms/'\n",
    "\n",
    "vis_df['link'] = (link_stem + vis_df['station_id'].map(int).map(str) + '_' +\n",
    "                  vis_df['par_id'] + '_' + vis_df['period'] + '.png')\n",
    "\n",
    "# Save \n",
    "out_csv = r'C:\\Data\\James_Work\\Staff\\Heleen_d_W\\ICP_Waters\\TOC_Trends_Analysis_2015\\Trends_Plots\\vis_data.csv'\n",
    "vis_df.to_csv(out_csv, index=False, encoding='windows-1252')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've converted the output from all this into a Google Fusion Table, which can be found **[here](https://www.googledrive.com/host/0BximeC_RweaeZlpSTWNrTHRyVG8)**. \n",
    "\n",
    "## 5. Summary to date\n",
    "\n",
    "This section summarises the work I've done so far with RESA2. The sub-headings can be compared to my RESA2 \"to do\" list, which can be found on the network here:\n",
    "\n",
    "K:\\Prosjekter\\langtransporterte forurensninger\\O-23300 - ICP-WATERS - HWI\\Database\\JamesS\\RESA2_To_Do_HWI.docx\n",
    "\n",
    "### 5.1. Review of data\n",
    "\n",
    "I've worked my way through all the ICP-Waters data in the database and have cleaned things up where possible. The notebooks [here](http://nbviewer.jupyter.org/url/www.googledrive.com/host/0BximeC_RweaeUy1jd2k3Nm1kdms/toc_trends_2015_data_cleaning.ipynb) and [here](http://nbviewer.jupyter.org/url/www.googledrive.com/host/0BximeC_RweaeUy1jd2k3Nm1kdms/toc_trends_2015_data_cleaning2.ipynb) describe the progress to date and the main outstanding issues. In particular, I've deleted and reloaded a large proportion of the  Czech water samples, many of which were associated with the wrong site codes. I've also identified a number of sites (mostly Swedish and Canadian) for which we have incomplete site metadata and/or very limited water chemistry measurements. Where data are missing, I've contacted the relevant Focal Centres to determine whether more complete information exists and can be made available.\n",
    "\n",
    "There are still a number of datasets on the network which have not been added to the database. Most of these are associated with locations where the main data contact is no longer very responsive (e.g. Hungary or Slovakia) and where there are issues regarding the raw data that has been supplied. In addition, datasets for Russia and the Netherlands have been supplied relatively recently, but in a format that will require significant work before they can be added to the database. I haven't got around to this yet.\n",
    "\n",
    "### 5.2. Review US sites\n",
    "\n",
    "I've tidied up the US sites in the database based on the information in John's e-mails - full details are in [this notebook](http://nbviewer.jupyter.org/url/www.googledrive.com/host/0BximeC_RweaeUy1jd2k3Nm1kdms/toc_trends_2015_data_cleaning.ipynb). There are stil a few (fairly minor) outstanding issues, but I've contacted John about these.\n",
    "\n",
    "### 5.3. Land cover proportions and mean catchment elevation\n",
    "\n",
    "I've added this information where possible and have also included a request for improved site metadata in the 2016 \"call for data\". I've already had responses from e.g. Italy and Switzerland, which have allowed me to substantially improve the station descriptions for these countires. Hopefully others will respond similarly later in the year.\n",
    "\n",
    "For the Norwegian sites, I've done a bit of watershed processing to refine the catchment properties (see [section 2 of this notebook](http://nbviewer.jupyter.org/url/www.googledrive.com/host/0BximeC_RweaeUy1jd2k3Nm1kdms/toc_trends_2015_data_cleaning2.ipynb#2.-Norway-sites)), but there is still a substantial amount of work required before we have a complete set of metadata for the Norwegian catchments. Heleen thinks this may be worth doing at some point, but it's on hold for now due to lack of time and resources.\n",
    "\n",
    "### 5.4. Correct Newfoundland data\n",
    "\n",
    "This has been done, as described in [section 5 of this notebook](http://nbviewer.jupyter.org/url/www.googledrive.com/host/0BximeC_RweaeUy1jd2k3Nm1kdms/toc_trends_2015_data_cleaning2.ipynb#5.-Newfoundland-sites).\n",
    "\n",
    "### 5.5. Add \"country\" as a metadata variable\n",
    "\n",
    "Done.\n",
    "\n",
    "### 5.6. Calculate distance from coast\n",
    "\n",
    "Done - see [section 4 of this notebook](http://nbviewer.jupyter.org/url/www.googledrive.com/host/0BximeC_RweaeUy1jd2k3Nm1kdms/toc_trends_2015_data_cleaning.ipynb#4.-Distance-to-coast) and [section 1 of this notebook](http://nbviewer.jupyter.org/url/www.googledrive.com/host/0BximeC_RweaeUy1jd2k3Nm1kdms/toc_trends_2015_data_cleaning2.ipynb#1.-Distance-to-coast) for details.\n",
    "\n",
    "### 5.7. Produce a map of the TOC trends sites for further checking\n",
    "\n",
    "Done. The map can be accessed [here](https://www.googledrive.com/host/0BximeC_RweaeZlpSTWNrTHRyVG8) and includes a simple visualisation of the results of the trend analyses (see below).\n",
    "\n",
    "### 5.8. Run the new trend analysis\n",
    "\n",
    "As described [here](http://nbviewer.jupyter.org/url/www.googledrive.com/host/0BximeC_RweaeUy1jd2k3Nm1kdms/updated_toc_trends_analysis.ipynb) and in this notebook, I've attempted to recode the entire trends analysis. This work is not finished yet (I need to extend the code to include a few more parameters), but the basic framework is complete and seems to be working OK. The code is easy to re-run and so, as long as Heleen, Don and John are happy with the baisc output, it should be fairly straightforward to repeat and adapt the trends analysis and necessary. It would be useful to have a discussion on how the output could be modified and extended to make it more useful.\n",
    "\n",
    "### 5.9. Send out 2016 \"call for data\"\n",
    "\n",
    "I've e-mailed the Focal Centre contacts and have had several replies already (e.g. from Italy and Switzerland). All the new data I've received has been added to the database.\n",
    "\n",
    "To check the progress of the 2016 call for any particular country, see the `contacts` sheet of the Excel file here:\n",
    "\n",
    "C:\\Data\\James_Work\\Staff\\Heleen_d_W\\ICP_Waters\\Call_for_Data_2016\\icpw_all_sites.xlsx\n",
    "\n",
    "which keeps track of all the messages I've sent and the replies I've received to date. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
